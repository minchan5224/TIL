### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 7주차 1일 06/22
---
## 순환 신경망 이해하기
> ### RNN(Recurrent Neural Network)개요
> - Recurrent : 몇번이나 반복해서 일어나는 일
> 
> 순환하는 신경망
>> 반복해서 돌아감
>> 
>> 순환을 위해서는 닫힌 경로(순환하는 경로)가 필요하다.
>> 
>> 과거 정보를 유지하며(기억하며) 새롭게 업데이트 할 수 있도록 구성
>
> ### [RNN 기본 구조](https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/)
> 
> ### Simple RNN
>> 기울기 소실 문제
>> 
>> 장기(long item)의존 관계를 잘 학습할 수 없음.
>> 
>> EX) Tom was watching TV in his room. Mary came into the room.
>> 
>> Mary said hi to [???]
>
> ### 게이트가 추가된 RNN(기존의 RNN의 단점을 보완)
>> LSTM(Long Short Term Memory)
>> 
>> GRU(Gated Recurrent Unit)
>> 
>
> ### [LSTM](https://wikidocs.net/22888)
>> Simple RNN과의 비교
>> - Input gate
>> 
>> - Output gate
>> 
>> - forget gate
>> 
>> - Memory cell
