### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 6주차 1일 06/15
---
> 지난 시간 수업 내용 복습
>
> ## 경사하강법
> 최적의 기울기(가중치)를 찾기위한 과정.
> - 경사가 내리막이였다가 오르막인 경우, 최적의 경사가 아닌 경우가 있다.
> 
> 2차 함수의 미분, 미분된 1차 함수의 기울기가 최소인 점이 비용함수가 최소인 지점이다.
> 
> ## 심층신경망
> 입력이 10개 Feature가 n개라면 n * 10개의 간선이 생성된다.
> - 간선의 생성을 제약하는 조건이 필요해질 수 있다(하이퍼파라미터?)
> 
> #### 은닉층이 2개인 신경망. 
>
>> 입력이 x라면 첫번째 은닉층의> 출력은 O_1 = F_1(x * W_1)
>> 
>> 두 번쨰 은닉층의 출력은 O_1 = F_2(O_1 * W_2)
>>
>> 최종 출력 output = F_3(O_2 * W_3)
>
> ### backpropagation
> 1. Feed Forward 수행
> 
> 2. Backpropagation 을 수행하면서 가중치 업데이트
> 
> 3. 1,2과정을 iteration 수행.
> 
> ## 케라스(텐서플로우에 내장)
> - Dense
>> Dense(30, input_dim=17, activation='relu')
>> 
>> 30 -> 출력 뉴런 수가 30개
>> 
>> input_dim = n -> 입력 뉴런 수가 n개
>> 
>> activation = '' -> 활성화 함수 설정.(str)
>>> 'linear' : 계산된 결과값이 그대로
>>> 
>>> 'relu' = '양수' hidden 층에서 문제가 안생기도록 주로 사용함.
>>> 
>>> 'sigmoid' : 각각이 0~1 s자로 표현되는 극잔적 함수, 2클래스 분류 문제에서 출력층에 주로 사용.
>>> 
>>> 'softmax' = 'softargmax' : 0~1이 최대값을 찾기위해 부드러운 확율 함수, 3이상 클래스 1분류 출력.
