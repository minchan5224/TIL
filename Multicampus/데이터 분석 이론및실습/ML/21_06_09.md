### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 5주차 3일 06/09
---
> ## [앙상블](https://velog.io/@fiifa92/%EC%95%99%EC%83%81%EB%B8%94Ensemble-%EA%B8%B0%EB%B2%95)
>> ### 유형
>> - 보팅(Voting)
>> 
>> - 배깅(Bagging)
>>> 랜덤포레스트가 대표적
>> 
>> - 부스팅(Boosting)
>>> 에이다 부스팅, 그래이던트 부스팅, GBM, XGBM, LightBGM등
>> 
>> - 스태킹(Stacking)
>> 
>> 넓은 의미 : 서로다른 알고리즘들을 결함
>> 
>> ### 특징
>> - 단일 모델의 약점을 다수의 모델을 결합하여 보완한다.
>> 
>> - 뛰어난 성능들만 구성하는 것만이 좋은 것은 아니다.(참고)
>> 
>> - 랜덤포레스트 등 뛰어난 부스트 알고리즘들은 모두 결정 트리 알고리즘을 기반으로 한다.
>> 
>> - 결정트리의 과적함 문제를 다수의 분류기를 결합해서 보완, 직관적인 분류 기준을 강화.
>> 
>> ### [보팅(Voting), 배깅(Bagging)개요](https://velog.io/@kjpark4321/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C-%EB%B6%84%EB%A5%98-3)
>> 
>> 보팅 : 다른 분류기 같은 데이터 셋
>>
>> 배깅 : 같은 분류기 다른 데이터 셋
>>
>> ### 보팅 유형
>> 하드 보팅과 소프트 보팅으로 나뉜다.
>> - 하드 보팅은 다수결(확률 아님, 1이다 아니면 2다.)로
>> 
>> - 소프트 보팅은 확률(1일확률, 2일 확률)의 평균으로 (predict_proba()메소드 이용해 class별 확률 결정)
>>
>> ### 배깅 - 랜덤 포레스트(Random Forest)
>> - 랜덤 포레스트는 여러개의 결정 트리 분류기가 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링해 개별적으로 학습을 수행한 뒤 최종적으로 모든 분류기가 보팅을 통해 예측결정을 하는 모델
>> 
>> - 랜덤 포레스트 알고리즘이 여러 개의 데이터 세트를 중첩되게 분리하는 것을 [부트 스트래핑](https://nittaku.tistory.com/389)이라 한다.
>> 
>>> #### 랜덤 포레스트 하이퍼 파라미터
>>> - n_estimator 결정트리의 개수(디폴트 10)
>>> 
>>> - max_depth
>>> 
>>> - max_features
>>> 
>>> - max_samples_leaf
>>
>> ## 부스팅
>> [AdaBoost와 그래디언트 부스트가 있다.](https://velog.io/@kjpark4321/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C-%EB%B6%84%EB%A5%98-3)
>
> ## 회귀(Regression)
> - 회귀 분석은 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용한 통계학 기법
>
> - 여러개의 독립변수(Feature)와 한개의 종속변수(결정값)간의 상관관계를 모델링하고 예측한다.
> 
> 머신러닝은 Feature와 결정값을 기반으로 최적의 회귀계수를 찾는다.
>
> ### 회귀 유형 구분.
>> 독립변수 개수
>> - 1개 : 단일 회귀
>> 
>> - 여러개 : 다중 회귀
>>
>> 회귀 계수의 결합
>> - 선형 : 선형 회귀(예측 성능이 비선형에 비해 좋다)
>> 
>> - 비선형 : 비선형 회귀
>> 
> ### 회귀분석이란
> 표본데이터(모집단의 일부분)을 분석해 모집단을 예측한다.
> 
> 결정적 모형(완벽한 비례식의 모형) : f(x),  x와 y에 대한 관계가 오차 없이 정확하다.
> 
> 통계적 모형 : f(x)+ε
>
> ### 선형회귀분석
> 선형 회귀(Linear regression)
> 
>> 독립변수와 종속변수가 선형적인 관계가 있다라는 가정하에 분석
>> 
>> 직선을 통해 종속변수를 예측하기 때문에 독립변수의 중요도와 영향력을 파악하기 쉽다.
>> 
>> 연속형 data의 input으로 연속형 output을 가진다.
> 
> 비선형 회귀(non-Linear regression)
>
> Square Error : (difference between prediction and real value)^2
>
> Least Mean Square(LMS) Error
>
> 최적의 회귀모델은 데이터 오류 합이 최소가 되는 것
> 
> 경사하강법은 계속해서 많이 보게 될것.
> 
> ### 실습 : 보스턴 주택 가격 회귀 구현.
