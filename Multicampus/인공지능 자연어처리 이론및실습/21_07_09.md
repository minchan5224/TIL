### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 9주차 4일 07/09
---
## 확률적 잠재 의미 분석
> 특이값 분해가 아닌 확률적 방법을 사용한다.
> 
> 토픽 모델링 가정 : 문서는 여러 주제로 구성되어 있고, 각 주제는 단어 집합으로 구성된다.
>
> 문서(d)가 주어지면 주제(z)는 확률 P(z|d)로 문서 내에 존재한다.
> 
> 주제(z)가 주어지면 단어(w)는 확률 P(w|z)로 주제 내에 존재한다.
>
> #### 확률적 잠재 의미 분석의 한계
> - 문서에 대한 확률P(D)에 대한 매개 변수가 없기 때문에 새 문서에 확률을 할당하는 방법을 모른다.
> 
> - 확률적 잠재 의미 분석의 파라미터는 분석할 문서 수에 따라 선형적으로 증가하기 때문에 오버피팅 되기 쉽다.
> 
> - 확률적 잠재 의미 분석은 거의 사용되지 않기 때문에 코드를 찾아보기 어렵다. 일반적으로 잠재 의미 분석보다 성능이 좋은 모델을 찾고자 할때 디리클레 할당을 사용한다.
> 
> ## 잠재 디리클레 할당(LDA)\
> 
> 주어진 문서에 대해 어떤 주제가 존재하는지에 대한 확률모형(토픽모델링)
> - LDA는 토픽별 단어의 분포, 문서별 토픽의 분포를 추정
> 
> - 문서가 생성될 확률인 사후분포에 기반한 변수를 추론하여 텍스트 내에 숨겨져 있는 주제를 찾아내는 방식
> 
> - 결과적으로 전체 텍스트 문사 집합의 주제(토픽)들, 각 텍스트 문서별 주제의 확률, 각 단어들이 각 주제에 포함될 확률을 도출(디리클레:확률분포명칭)
> 
> - LDA는 토픽의 단어 분포와 문서의 토픽 분포의 결합으로 문서 내 단어들이 생성된다고 가정.
> 
> - 학습은 실제 관찰 가능한 말뭉치(문서와 단어)를 가지고 우리가 알고 싶은 토픽의 단어 분포, 문서의 토픽 분포를 추정하는 과정.
> 
> - 잠재(Latent) : 사전적인 의미는 "잠재적인, 숨어있는". 우리가 직접 관찰 할 수 있는것은 문서 내용뿐. α, β, θ, z는 모두 감춰진 파라미터
> 
> - 디리클레(Dirichlet) : 19세기 독일 수학자의 이름. 디리클레 분포(Dirichlet Distribution)를 사용하고 있음.(θ를 결정할 때 α를 파라미터로 디리클레 분포를 사용)
> 
> - 할당(Allocation): '할당'. 각 단어를 결정할 때, θ에 대한 다항 분포(Multinomial Distribution)로 주제를 '할당'한 뒤 그 주제로부터 단어를 
