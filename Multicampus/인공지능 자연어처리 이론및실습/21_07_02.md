### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 8주차 4일 07/02
---
## 문서 요약(Text Summarization)
> 문서 요약은 문서에서 중요한 문장을 자동으로 추출하는 과정
> 
> 중요한 문장을 추출한다 => 문장의 중요성을 어떻게 판단한 것인가
> 
> #### 문장 요약의 필요성
> - 대량 데이터 처리 가능
>> 문장 요약을 활용해 대량 데이터를 분석할 수 있다. 직접 문서를 읽고 주요 용어를 수동으로 식별 할 수 있지만 많은 시간이 소요된다. 이 작업을 자동화 하면 다른 더 중요한 작업에 집중할 수 있다.
>
> - 추출의 일관성
>> 문장 요약은 규칙과 사용자가 정의한 매개변수를 기반으로 작동한다. 따라서 텍스트 분석을 수동으로 수행 할 때 나타나는 불일치를 고려할 필요가 없다.
>
> - 실시간 분석 가능
>> 소셜 미디어 게시물, 고객 리뷰, 설문 조사 또는 고객 지원에 대한 문장 요약을 실시간으로 수행하고 제품에 대한 의견을 얻을 수 있다.
>
> ### Luhn Summarize
> 단어의 중요도는 사용 빈도로 측정. 작가는 중요한 단어를 반복해서 사용한다는 사실에 기반
>
> #### 중요 단어 (Significant Words)
> 
> #### 문장 중요도 (Significance factor)
> - 중요 단어를 포함하는 경우
> 
> - 중요 단어가 등장하는 처음과 끝사이 단어들 중 중요 단어의 상대 비율
>> 예시 : 중요단어 4개, 윈도내 단어 7개 ( = (4^2)/7 = 2.3)
>
> #### Luhn Summarize 절차
> 1. 토큰화
> 
> 2. 중요단어 결정
> - 문서내 단어빈도 비율 (0.001 < 단어빈도비율 < 0.5)
> 
> 3. 문장 중요도 계산
> - 문장내 포함된 중요단어 상대비율 계산
> 
> 4. 문서요약
> - 문장 중요도 순위별 출력
> 
> ### TextRank 활용 문서 요약 (TextRank: Bringing Order into Texts)
> 
> #### 4 Sentence Extraction
>> 문장을 추출하는 것은 키워드 추출과 유사
>> 
>> 두 방법(키워드 추출, 문장 추출) 모두 텍스트를 대표하는(representative) 시퀀스를 식별하는 것을 목표로 함
>> 
> #### 4.1 TextRank for Sentence Extraction
>> 문장 내 co-occurrence에 기반한 관계 정의는 적용할 수 없음(문장이기 때문)
>> 
>> 문장 간 "유사성"이 있는 경우 connection있다고 정의. 유사성은 content overlap함수로 측정
>> 
>> 텍스트 내 다양한 문장사이의 관계 강도가 결정되고, 이를 역순으로 정렬하여 텍스트를 요약
>> 
> #### 5 Why TextRank Works
>> 링크하는 다른 텍스트 단위의 "중요성"을 바탕으로 텍스트 단위를 평가
>> 
>> 사람이 담화를 이해하는 과정에서 주어진 문맥을 형성하는 모델을 근사
>> 
> #### 6 Conclusions
>> Textrank는 깊은 언어지식이나 도메인 별 corpora를 필요로 하지 않고 다른 도메인, 장르, 언어에 적용할 수 있다.
>
> #### 키워드 추출 vs 문서 요약
> 핵심 키워드 추출 : 윈도가 이동하며 그래프 생성
> 
> 문서 요약 : 모든 문장간 유사도를 기준으로 그래프 생성
> 
> #### Textrank 과정 : 그래프 생성
> 딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나.
> 
>                                  ↓ 문장 토큰화
> 
> 문장 1 : 딸기 바나나 사과 파인애플 수박
>
> 문장 2: 바나나 사과 딸기 포도
> 
> 문장 3: 복숭아 수박
> 
> 문장 4: 파인애플 사과 딸기 바나나
> 
> 1번 문장과 2번 문장의 유니크한 텍스트의 갯수는 6개이며 서로 겹치는 텍스트는 3개 다 즉 3/6 = 0.5 의 간선이 형성.
> 
> 나머지 문장들도 전부 같은 방식으로 간선을 연결하며 겹치는 텍스트가 없는 경우 간선이 형성되지 않는다.(자카드 유사도 사용)
> 
>> ##### [자카드 유사도 (Jaccard index)](https://lsjsj92.tistory.com/443)
>> 두 문장을 각각 단어의 집합으로 만든 뒤 두 집합을 통해 유사도를 측정하는 방식중 하나
>> 
>> 두 집합의 교집합을 두 집합의 합집합으로 나눠준다.
>> - 문서 혹은 문장간 유사도 측정(겹치는 토큰의 비율)
>
> #### Textrank 과정 : 그래프 생성
> 위에서 구한 간선의 수치를 문장간 유사도로 사용한다.
> ```
> 문장 1 ↔ 문장 2 : 0.50
> 문장 1 ↔ 문장 3 : 0.167
> 문장 1 ↔ 문장 4 : 0.80
> 문장 2 ↔ 문장 4 : 0.60
> ```
> 
> - 엣지 생성.
> ```
>        엣 지                        수 식                                  엣지가중치
> 문장 1 → 문장 2 | (문장 1 ↔ 문장 2 유사도)/(문장 1 전체 유사도) | 0.5 / (0.5 + 0.167 + 0.8) = 0.341
> 문장 1 → 문장 3 | (문장 1 ↔ 문장 3 유사도)/(문장 1 전체 유사도) | 0.167 / (0.5 + 0.167 + 0.8) = 0.114
> 문장 1 → 문장 4 | (문장 1 ↔ 문장 4 유사도)/(문장 1 전체 유사도) | 0.8 / (0.5 + 0.167 + 0.8) = 0.545
> 문장 2 → 문장 1 | (문장 2 ↔ 문장 1 유사도)/(문장 2 전체 유사도) | 0.5 / (0.5 + 0.6) = 0.455
> 문장 2 → 문장 4 | (문장 2 ↔ 문장 4 유사도)/(문장 2 전체 유사도) | 0.6 / (0.5 + 0.6) = 0.545
> 문장 3 → 문장 1 | (문장 3 ↔ 문장 1 유사도)/(문장 3 전체 유사도) | 0.167 / (0.167) = 1
> 문장 4 → 문장 1 | (문장 4 ↔ 문장 1 유사도)/(문장 4 전체 유사도) | 0.8 / (0.8 + 0.6) = 0.571
> 문장 4 → 문장 2 | (문장 4 ↔ 문장 2 유사도)/(문장 4 전체 유사도) | 0.6 / (0.8 + 0.6) = 0.429
> ```
> #### Textrank 과정 : 행렬로 계산하기
> ```
> 노드   |  최초 스코어
> 문장 1 |   1.467      S(문장1) = (1-0.85) + 0.85 x (0.501 + 0.167+0.799) = 1.397
> 문장 2 |   1.100      S(문장2) = (1-0.85) + 0.85 x (0.5 + 0.601) = 1.086
> 문장 3 |   0.167      S(문장3) = (1-0.85) + 0.85 x (0.167) = 0.292
> 문장 4 |   1.400      S(문장4) = (1-0.85) + 0.85 x (0.8 + 0.6) = 1.340
>
> 위 연산은 아래처럼 볼 수 있다.
>
>          문장 1 | 문장 2 | 문장 3 | 문장 4 
> 문장 1 |  0.000 | 0.500  | 0.167 |  0.800 
> 문장 2 |  0.501 | 0.000  | 0.000 |  0.600 
> 문장 3 |  0.167 | 0.000  | 0.000 |  0.000 
> 문장 4 |  0.799 | 0.601  | 0.000 |  0.000  
>             ↓       ↓        ↓        ↓
>         S(문장1) S(문장2)  S(문장3)  S(문장4)
> ```
> 계속해서 순환하며 스코어를 갱신하는 것이 어제 했던 방식과 유사하다.
>
> 대신 단어에 대한 스코어가 아닌 문장에 대한 스코어라는 것이 가장 큰 차이점이다.
> 
