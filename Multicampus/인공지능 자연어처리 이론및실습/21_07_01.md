### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 8주차 2일 06/30
---
## 핵심 키워드 추출(Keyword Extraction)
> 키워드 추출은 문서에서 가장 중요한 단어를 자동으로 추출하는 과정이다.
> - 중요한 단어를 추출한다 => 단어의 중요성을 어떻게 판단할 것인가.
> 
> #### 핵심 키워드 추출의 필요성
> 대량 데이터 처리 가능
>> 키워드 추출을 활용해 대량 데이터를 분석할 수 있다. 직접 문서를 읽고 주요 용어를 수동으로 식별할 수 있지만 많은 시간이 소요된다.
>> 
>> 이 작업을 자동화하면 다른 더 중요한 작업에 집중 할 수 있다.
>> 
> 추출의 일관성
>> 키워드 추출은 규칙과 사용자가 정의한 매개변수를 기반으로 작동한다.
>> 
>> 따라서 텍스트 분석을 수동으로 수행 할 때 나타나는 불일치를 고려할 필요가 없다.
>>
> 실시간 분석 가능
>> 소셜 미디어 게시물, 고객 리뷰, 설문 조사 또는 고객 지원에 대한 키워드 추출을 실시간으로 수행하고 제품에 대한 의견을 얻을 수 있다.
>> 
> #### 통계적 접근
> 단어빈도
>> 단어의 등장 빈도를 활용하여 중요 단어를 추출
>> 
>> 단어 빈도 접근 방식은 문서를 단순한 단어 모음으로 간주
>> 
>> 단어의 의미, 구조, 문법 및 단어 순서를 고려하지 않음
>> 
> 연어 / 동시발생
>> 단어의 의미구조를 이해하기 위해서 N-gram과 같은 통계기법을 활용하여 연어나 동시발생 단어를 하나의 단어로 처리할 수 있음
>> 
>> 연어는 연이어 함께 자주 등장하는 단어 묶음(예,"고객 서비스")
>> 
>> 동시 발생(co-occurrence)은 동일 코퍼스 내에 함께 등장하는 단어 묶음. 연어와 다르게 반드시 단어가 인접할 필요 없음.
>
> ### TF-IDF 활용 핵심 키워드 추출
> #### TF-IDF 활용 핵심 키워드 추출 절차
>> 1. 토큰화 : 문서 집합을 문서별로 토큰화
>> 
>> 2. TF-IDF 계산 : 문서의 단어별 TF-IDF score 계산
>> 
>> 3. TF-IDF score 가 높은순으로 추출 : TF-IDF score가 높은 순으로 상위부터 추출
> 
> ### TextRank 활용 키워드 추출
> 단어의 중요도 판단 : TextRank
> 
> 문서를 그래프로 만들고 중요도를 계산한다.
> - 구글의 페이지 랭크 알고리즘에서 나왔다(나를 참조하는 페이지가 많아질수록 점수가 높아진다(중요도가 높아진다.)
> 
> TextRank: BringingOrder into Texts
> - Abstract
>> 그래프 기반 Ranking 모델 Textrank
>> 
>> 키워드와 문장 추출을 위한 비지도 학습 방법을 제안
>> 
> - 1 Introduction
>> 그래프 기반 랭킹 알고리즘은 구글 PageRank에서 사용됨(웹 분석에 성공적으로 적용)
>> 
>> 그래프 기반 랭킹 알고리즘은 그래프의 각 vertex의 중요도를 결정하는 방법
>> 
> - 2 The TextRank Model
>> 그래프 기반 랭킹 알고리즘은 그래프 속 vertex(노드)의 중요도를 결정하는 방법
>> 
>> 기본 아이디어는 (하나의 vertex가 다른 vertex에 연결되면) "투표"혹은 "추천"
>> 
>> 많은 득표를 한 vertex가 중요한 vertex임을 의미
> - 2.1 Undirected Graphs
>> Undirected그래프의 경우 더 점진적 수렴 곡선을 가짐(더 빠르게 수렴한다.)
> - 2.2 Weighted Graphs
>> NLP문제에서 weighted를 사용하는게 유리, Undirected / Weighted graph는 성능상 차이가 없다.
> 2.3 Text as a Graph
>> 주어진 텍스트의 핵심 키워드를 추출할 수 있음
>> 
>> 주어진 텍스트의 핵심 문장을 식별할 수 있음
> - 2 The TextRank Model
> 
> - 3 Keyword Extraction
>> 키워드 추출은 문서를 대변할 수 있는 단어 집합을 자동으로 식별하는것
> - 3.1 TextRank for Keyword Extraction
>> 1. 텍스트는 품사가 태깅되어 토큰화 됨
>> 
>> 2. 단어 윈도(window of words)에 동시 등장한 토큰 사이는 엣지를 추가하여 그래프 생성
>> 
>> 3. 0.0001을 threshold로 20~30회 반복
> - 3.2 Evaluation
>> Textrank 방식이 정밀도(Precision)와 F-measure 에서 가장 높지만 재현율(Recall)은 지도학습 방법에 비해 높지 않음
>>
>> 그리고 windows가 클수록 정확도는 낮아짐(=멀리 떨어져 있는 단어가 관계를 정의 할 만큼 강력하지 않음)
> - 4 Why TextRank Works
>> 텍스트 단위(vertex)의 로컬 컨텍스트를 고려할 뿐 아니라, 전체 텍스트(그래프)에서 재귀적으로 정보를 고려하기 때문에 Textrank가 잘 작동
>> - (문장 내의 좌우 정보만 보는 것이 아닌 전체를 살핀다)
>> 
>> 링크하는 다른 텍스트 단위의 "중요성"을 바탕으로 텍스트 단위 평가
> - 5 Conclusions
>> Textrank는 깊음 언어지식이나 도메인 별 corpora를 필요로 하지 않고, 다른 도메인, 장르, 언어에 적용할 수 있음
>
> ### Textrank 과정: 그래프 생성
> 문장에서 단어를 추출 후 윈도우(묶음?)를 이용해 그래프를 생성한다.
> - 바나나 딸기 사과 파인애플 
>
> 생성된 그래프의 스코어를 전부 (1,0)으로 셋팅한다.
>
> ### Textrank 과정: 행렬로 계산하기 
> 인접노드를 찾는다. 
> - 각 노드에서 연결된 엣지(간선)의 가중치를 구한다(가중치는 : 스코어/총 엣지수 다. 각 노드의 간선별 계산.)
> 
> - 자신이 받는 값은 연결된 간선의 반대편의 가중치다.
>
> - 공식을 이용해 스코어를 갱신하며 과정을 반복한다.
