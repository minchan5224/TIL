### 멀티캠퍼스 인공지능 자연어처리[NLP]기반 기업 데이터 분석.
- 8주차 3일 07/01
---
## Textrank 실습
> ```Python
> tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']
> nodes = ['바나나', '사과', '파인애플', '딸기']
> vocab = nodes # set(token) 해도댐.
> vocab2idx = {vocab[i]:i for i in range(0, len(vocab))} #vocab을 인덱스로 변환
> idx2vocab = {i:vocab[i] for i in range(0, len(vocab))} #인덱스를 vocab으로 변환
> ```
> 
> ```
> import numpy as np
> import math
> vocab_len = len(vocab)
> 
> # 토큰별로 그래프 edge를 Matrix 형태로 생성
> # 처음엔 0으로 생성. dtype=np.float32 안하면 기본적으로 np.float64로 생성된다.(메모리 사이즈 차이)
> weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)
> 
> # 각 토큰 노드별로 스코어 1로 초기화 하기전 0으로 선언
> score = np.ones((vocab_len),dtype=np.float32)
> print(score)
> 
> # coocurrence를 판단하기 위한 window 사이즈 설정
> window_size = 2
> 
> # wincow_size를 3개 이상 으로 할 때 중복 작업이 발생한다.
> # 중복 작업을 건너뛰기 위해 coocurrences를 한다(위치값 기억하기 위해.)
> covered_coocurrences = [] 
> 
> # tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']
> for window_start in range(0, (len(tokens) - window_size + 1)):
>     window = tokens[window_start : window_start + window_size]
>     for i in range(window_size):
>         for j in range(i+1, window_size):
>             if window[i] in vocab2idx.keys() and window[j] in vocab:
>                 index_i, index_j = i + window_start, j + window_start
> 
>                 if (index_i, index_j) not in covered_coocurrences:
>                     # 각 토큰 노드연결 1로 초기화
>                     weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1
>                     weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1
>                     covered_coocurrences.append((index_i, index_j))
> 
> for i in range(vocab_len): # 노드별 가중치 셋팅
>     # 초기 스코어:1 이다. (스코어 = 스코어/해당 노드 연결된 노드수)
>     row_sum = weighted_edge[i].sum()
>     print(f"{i} : {row_sum}") # 그냥 값 볼라고 사용
>     weighted_edge[i] = weighted_edge[i]/row_sum
> 
> ```
> 위 코드 내부 파라미터 값을 조절하며 n개의 묶음으로 할 지 설정 가능
> 
> ```
> MAX_ITERATIONS = 50
> d = 0.85
> threshold = 0.0001
> 
> for iter in range(MAX_ITERATIONS):
>     prev_score = np.copy(score)
>     for i in range(vocab_len):
>         summation = 0
>         for j in range(vocab_len):
>             summation += weighted_edge[j][i] * score[j]
>         score[i] = (1-d) + d*summation
>     print(" ***** score ***** ")
>     print(score)
>     if np.sum(np.fabs(prev_score - score)) <= threshold:
>         break
> print(" ***** final ***** ")
> print(score)
>```
> threshold의 경우 스코어의 이전 값고 현재값을 비교하며 차이가 0.001이하라면 중단시킨다. 더이상은 의미가 없기때문
> 
> ```
> sorted_index = np.flip(np.argsort(score),0)
> # np.argsort(score)는 score의 인덱스를 값이 작은 순으로 정렬해 리스트로 반환한다.
> # np.flip() 리스트 거꾸로 한다고 생각하면 편함.
> 
> print("\n=== 핵심키워드 ===")
> n = 4 # 갯수제한
> for i in range(0,n):
>     print(str(idx2vocab[sorted_index[i]])+" : " + str(score[sorted_index[i]]))
> ```
> 값을 채운 스코어를 오름차순으로 만든뒤 뒤집는다.
> 
> 그 후 원하는 범위까지 키워드를 출력한다.
> 
> 오늘은 여기까지
