{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import os, re\n",
    "import numpy as np\n",
    "import urllib.request as ur\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버거킹 매장 주소 습득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_name = []\n",
    "stores_address = []\n",
    "stores_phonenum = []\n",
    "url = 'https://www.burgerking.co.kr/'\n",
    "chromedriver = './python_ex_100/selenium/chromedriver'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "\n",
    "driver.get(url)\n",
    "store_menu = driver.find_elements_by_css_selector(\"li.menu_open\")[0]\n",
    "store_menu.click() #매장소개 클릭\n",
    "time.sleep(0.5)\n",
    "store_find = store_menu.find_elements_by_css_selector(\"a\")[0]\n",
    "store_find.click() # 매장찾기 클릭\n",
    "time.sleep(0.5)\n",
    "# 아래부터 \"https://www.burgerking.co.kr/#/store\"임\n",
    "address_select = driver.find_elements_by_css_selector(\"ul.item3\")[0]\n",
    "address_select = address_select.find_elements_by_css_selector(\"button\")[2]\n",
    "address_select.click() # 지역검색 클릭\n",
    "time.sleep(0.5)\n",
    "print('서울시내 매장 검색')\n",
    "address_select = driver.find_elements_by_css_selector(\"div.form_list > select.st04\")[0]\n",
    "address_select = driver.find_elements_by_css_selector(\"option\")[1]\n",
    "address_select.click() # 서울특별시 클릭.\n",
    "\n",
    "time.sleep(1)\n",
    "store_object = driver.find_elements_by_css_selector(\"ul.list02 > li\")\n",
    "print('매장 정보 수집 끝')\n",
    "for i, j in enumerate(store_object):\n",
    "    stores_name.append(j.find_element_by_css_selector(\"div.shop_detail02 > p\").text)\n",
    "    \n",
    "    temp=j.find_elements_by_css_selector(\"div.subinfo > p\")\n",
    "    \n",
    "    if temp[0].text == '':\n",
    "        stores_address.append('주소없음')\n",
    "    else:\n",
    "        stores_address.append(temp[0].text)\n",
    "    if temp[1].text == '':\n",
    "        stores_phonenum.append('번호없음')\n",
    "    else:\n",
    "        stores_phonenum.append(temp[1].text)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "store_dict = {\"매장명\":stores_name, \"매장주소\":stores_address, \"전화번호\":stores_phonenum}\n",
    "\n",
    "    \n",
    "\n",
    "create_ex = pd.DataFrame(store_dict)\n",
    "\n",
    "create_ex.to_csv('./data/bugerking/bugerking.csv',encoding='utf-8-sig')\n",
    "print('매장 정보 저장 끝')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 롯데리아 매장정보 습득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_name = []\n",
    "stores_address = []\n",
    "stores_phonenum = []\n",
    "page_start=3\n",
    "url = 'http://www.lotteria.com/Shop/Shop_List.asp'\n",
    "chromedriver = './python_ex_100/selenium/chromedriver'\n",
    "t = True\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "# driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "driver.get(url)\n",
    "store_menu = driver.find_elements_by_css_selector(\"select#locationSelect > option\")[1]\n",
    "\n",
    "store_menu.click() #매장소개 클릭\n",
    "time.sleep(0.5)\n",
    "driver.find_element_by_css_selector(\"div.locationSelectWrap > a\").click()\n",
    "time.sleep(1.5)\n",
    "\n",
    "end_page = True\n",
    "while end_page:\n",
    "    if stores_name != []:\n",
    "        page_start = 2\n",
    "    for i in driver.find_elements_by_css_selector(\"tr.shopSearch\"):\n",
    "        idx, stroe_code = tuple(re.sub(\"(goView\\()*(\\); return false;)*(\\,)*(\\')*\",\"\",i.find_element_by_css_selector(\"a\").get_attribute('onclick')).split())\n",
    "        response = requests.get(\"http://www.lotteria.com/Shop/Shop_View.asp?Idx=\"+idx+\"&StoreCode=\"+stroe_code)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        stores_name.append(soup.select_one(\"div#content div.h3_box\").text.strip())\n",
    "        stores_address.append(soup.select_one(\"td.rt\").text.strip())\n",
    "        stores_phonenum.append(re.sub(\"( )*\",\"\",soup.select_one(\"td.phone\").text.split(\"/\")[0]))\n",
    "\n",
    "    driver.find_elements_by_css_selector(\"div.paging_basic a\")[2].click()\n",
    "    \n",
    "    time.sleep(2.5)\n",
    "    for next_page in range(page_start,12):\n",
    "        page_numbers = driver.find_elements_by_css_selector(\"div.paging_basic a\")\n",
    "        for i in driver.find_elements_by_css_selector(\"tr.shopSearch\"):\n",
    "            idx, stroe_code = tuple(re.sub(\"(goView\\()*(\\); return false;)*(\\,)*(\\')*\",\"\",i.find_element_by_css_selector(\"a\").get_attribute('onclick')).split())\n",
    "            response = requests.get(\"http://www.lotteria.com/Shop/Shop_View.asp?Idx=\"+idx+\"&StoreCode=\"+stroe_code)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            if re.sub(\"( )*\",\"\",soup.select_one(\"td.phone\").text.split(\"/\")[0]) in stores_phonenum:\n",
    "                end_page = False\n",
    "                print('수집 끝')\n",
    "                break\n",
    "            stores_name.append(soup.select_one(\"div#content div.h3_box\").text.strip())\n",
    "            stores_address.append(soup.select_one(\"td.rt\").text.strip())\n",
    "            stores_phonenum.append(re.sub(\"( )*\",\"\",soup.select_one(\"td.phone\").text.split(\"/\")[0]))\n",
    "\n",
    "        if end_page == False:\n",
    "            break\n",
    "        page_numbers[next_page].click()\n",
    "        time.sleep(2.5)\n",
    "    \n",
    "store_dict = {\"매장명\":stores_name, \"매장주소\":stores_address, \"전화번호\":stores_phonenum}\n",
    "create_ex = pd.DataFrame(store_dict)\n",
    "\n",
    "create_ex.to_csv('./data/lotteria/lotteria.csv',encoding='utf-8-sig')\n",
    "print('매장 정보 저장 끝')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv에 저장된 점포 정보 이용해 네이버에서 검색가능한 id추출.\n",
    "- 엑셀명 자동 수정기능 없음 알아서 기입해야함\n",
    "- store_name: 변수의 매장명 아직 직접 수정해야함\n",
    "- 정보 수집후 결측치 직접 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_infos = pd.read_csv(\"./data/bugerking/bugerking.csv\", index_col = 0) # 버거킹\n",
    "store_name = '버거킹%20' # 버거킹\n",
    "\n",
    "# store_infos = pd.read_csv(\"./data/lotteria/lotteria.csv\", index_col = 0) # 롯데리아\n",
    "# store_name = '롯데리아%20' # 롯데리아\n",
    "\n",
    "url = 'view-source:https://pcmap.place.naver.com/restaurant/list?level=top&entry=pll&query='\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "store_ids = []\n",
    "for i in store_infos['매장명']:\n",
    "    if i[-1] == '점':\n",
    "        driver.get(url+store_name+i)\n",
    "    else :\n",
    "        driver.get(url+store_name+i+'점')\n",
    "    time.sleep(5)\n",
    "    result = driver.find_elements_by_css_selector(\"td.line-content\")[29].text\n",
    "    \n",
    "    try :\n",
    "        store_id = re.findall(\"(?<=\\\"id\\\":\\\"RestaurantSummary:).*(?=\\\",\\\"typename\\\":\\\"RestaurantSummary\\\")\",result)\n",
    "        if store_id == []:\n",
    "            store_ids.append('id 없음')\n",
    "        else :\n",
    "            store_ids.append(store_id)\n",
    "        print(store_id)\n",
    "    except IndexError:\n",
    "        store_ids.append('오류')\n",
    "        \n",
    "store_infos[\"id\"] =  store_ids\n",
    "store_infos.to_csv('./data/bugerking/bugerking_2.csv',encoding='utf-8-sig') # 버거킹\n",
    "# store_infos.to_csv('./data/lotteria/lotteria_2.csv',encoding='utf-8-sig') # 롯데리아"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 검색을 위한 id 와 csv의 점포명 비교, 리뷰 갯수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_infos = pd.read_csv(\"./data/bugerking/bugerking_2.csv\", index_col = 0) # 버거킹\n",
    "# store_infos = pd.read_csv(\"./data/lotteria/lotteria_2.csv\", index_col = 0) # 롯데리아\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "# driver = webdriver.Chrome(chromedriver)\n",
    "review_counts=[]\n",
    "for i, j in zip(store_infos['id'], store_infos['매장명']):\n",
    "    url = 'https://m.place.naver.com/restaurant/'+i[2:-2]+'/review/visitor'\n",
    "    driver.get(url)\n",
    "    try :\n",
    "        result = driver.find_element_by_css_selector(\"div#app-root h1._2msz7\")\n",
    "        result_2 = driver.find_element_by_css_selector(\"div.place_section div._1XXGh\")\n",
    "        review_counts.append(int(re.sub(\",*\",\"\",result_2.text.split()[0][:-1])))\n",
    "        print(j)\n",
    "        print(result.text)\n",
    "        print(int(re.sub(\",*\",\"\",result_2.text.split()[0][:-1])))\n",
    "    except :\n",
    "        review_counts.append(0)\n",
    "        \n",
    "    \n",
    "store_infos[\"review\"] =  review_counts\n",
    "store_infos.to_csv('./data/bugerking/bugerking_3.csv',encoding='utf-8-sig') # 버거킹\n",
    "# store_infos.to_csv('./data/lotteria/lotteria_3.csv',encoding='utf-8-sig') # 롯데리아\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리뷰 갯수 기준 상위 50개의 점포정보 최종 저장\n",
    "- 가정 : 네이버 리뷰가 많으면 요기요 리뷰도 많을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_process(n):\n",
    "    return n[2:-2]\n",
    "bugerking_data = pd.read_csv(\"./data/bugerking/bugerking_3.csv\", index_col = 0)\n",
    "lotteria_data = pd.read_csv(\"./data/lotteria/lotteria_3.csv\", index_col = 0)\n",
    "lotteria_data['id'] = lotteria_data['id'].apply(str_process) # id 형식 변경\n",
    "bugerking_data['id'] = bugerking_data['id'].apply(str_process) # id 형식 변경\n",
    "bugerking_data.sort_values('review', ascending = False)[:50].to_csv('./data/bugerking/bugerking_data.csv',encoding='utf-8-sig')\n",
    "lotteria_data.sort_values('review', ascending = False)[:50].to_csv('./data/lotteria/lotteria_data.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 매장별 요기요 상세페이지 습득, 저장(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yogiyo_store_url_find(address_list, name_list, brand_name, brand_type):\n",
    "#     address_list = [i for i in pd.read_csv(\"./data/lotteria/lotteria_data.csv\", index_col = 0)['매장주소']]\n",
    "#     name_list = [i for i in pd.read_csv(\"./data/lotteria/lotteria_data.csv\", index_col = 0)['매장명']]\n",
    "\n",
    "    url = 'https://www.yogiyo.co.kr/mobile/?gclid=CjwKCAjw47eFBhA9EiwAy8kzNGbtPeXf1_78lj3sV4UkKJLnuA11hYXcCfZ9B62XZa8clZapkaMuixoCsaUQAvD_BwE#/'\n",
    "    url_find = []\n",
    "\n",
    "    re_try = False\n",
    "    chromedriver = './python_ex_100/selenium/chromedriver'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "    driver = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "#     driver = webdriver.Chrome(chromedriver)\n",
    "    for store_address, store_name in zip(address_list, name_list):\n",
    "        driver.get(url)\n",
    "        time.sleep(0.5)\n",
    "        driver.find_elements_by_css_selector(\"div.input-group input\")[0].click()\n",
    "        time.sleep(0.5) # 검색 탭 클릭\n",
    "        driver.find_elements_by_css_selector(\"div.input-group  button.btn-search-location-cancel.btn-search-location.btn.btn-default\")[0].click()\n",
    "        time.sleep(0.5) # 이미 채워져있는 텍스트 지우는 X버튼 클릭\n",
    "        driver.find_elements_by_css_selector(\"div.input-group input\")[0].send_keys(store_address)\n",
    "        time.sleep(0.5) # 검색에 필요한 키워드 타이핑\n",
    "        driver.find_elements_by_css_selector(\"div.input-group  button.btn.btn-default.ico-pick\")[0].click()\n",
    "        time.sleep(3) # 검색버튼 클릭\n",
    "        search=driver.find_elements_by_css_selector(\"div.input-group ul.dropdown-menu.ng-scope.am-flip-x.bottom-left > li\")\n",
    "        # 검색 클릭시 하위리스트들 가져오기(검색 클릭시 바로 페이지가 넘어가는 경우도 있다.)\n",
    "        if len(search) >= 3: # 리스트 길이가 3이상일때\n",
    "            search[2].click() # 첫번째 주소 클릭시킴\n",
    "        else :\n",
    "            pass # 없다면 그냥 패스\n",
    "        time.sleep(1)\n",
    "        driver.find_elements_by_css_selector(\"div.list-option-inner option\")[4].click()\n",
    "        # 거리순 옵션 클릭\n",
    "\n",
    "        time.sleep(1)\n",
    "        restaurants = driver.find_elements_by_css_selector(\"div.ng-scope div.restaurant-list div.col-sm-6.contract\")\n",
    "        # 매장 정보들 전부 습득\n",
    "        # 첫 로딩에 나온 매장만 가져온다.\n",
    "        time.sleep(2)\n",
    "        for restaurant in restaurants: # 가져온 매장리스트 기준으로 타깃(롯데리아) 주소 획득시작\n",
    "            if brand_type == 0 and brand_name+'-{}'.format(store_name) in restaurant.text: #버거킹일때\n",
    "                re_try = False\n",
    "                restaurant.find_element_by_css_selector(\"div.col-sm-6.contract div.item.clearfix\").click()\n",
    "                print(store_name, driver.current_url)\n",
    "                url_find.append([store_name, store_address, driver.current_url])\n",
    "                break\n",
    "            elif brand_type == 1 and brand_name in restaurant.text: # 롯데리아 일때\n",
    "                re_try = False\n",
    "                restaurant.find_element_by_css_selector(\"div.col-sm-6.contract div.item.clearfix\").click()\n",
    "                print(store_name, driver.current_url)\n",
    "                url_find.append([store_name, store_address, driver.current_url])\n",
    "                break\n",
    "            else :\n",
    "                re_try = True\n",
    "\n",
    "\n",
    "        if re_try == True: # 찾지 못했을때 키워드를 변경하고 재검색한다.\n",
    "            print(\"재검색\")\n",
    "            driver.find_elements_by_css_selector(\"div.input-group input\")[0].click()\n",
    "            time.sleep(0.5)\n",
    "            driver.find_elements_by_css_selector(\"div.input-group  button.btn-search-location-cancel.btn-search-location.btn.btn-default\")[0].click()\n",
    "            time.sleep(0.5)\n",
    "            driver.find_elements_by_css_selector(\"div.input-group input\")[0].send_keys(store_address+' '+brand_name)\n",
    "            time.sleep(0.5)\n",
    "            driver.find_elements_by_css_selector(\"div.input-group  button.btn.btn-default.ico-pick\")[0].click()\n",
    "            time.sleep(2)\n",
    "            re_search=driver.find_elements_by_css_selector(\"div.input-group ul.dropdown-menu.ng-scope.am-flip-x.bottom-left > li\")\n",
    "            if len(re_search) >= 3:\n",
    "                re_search[2].click()\n",
    "            else :\n",
    "                pass\n",
    "            time.sleep(2)\n",
    "            driver.find_elements_by_css_selector(\"div.list-option-inner option\")[4].click()\n",
    "            time.sleep(0.5)\n",
    "            restaurants = driver.find_elements_by_css_selector(\"div.ng-scope div.restaurant-list div.col-sm-6.contract\")\n",
    "            time.sleep(2)\n",
    "            for restaurant in restaurants:\n",
    "                if brand_type == 0 and brand_name+'-{}'.format(store_name) in restaurant.text: #버거킹일때\n",
    "                    re_try = False\n",
    "                    restaurant.find_element_by_css_selector(\"div.col-sm-6.contract div.item.clearfix\").click()\n",
    "                    print(store_name, driver.current_url)\n",
    "                    url_find.append([store_name, store_address, driver.current_url])\n",
    "                    break\n",
    "                elif brand_type == 1 and brand_name in restaurant.text: # 롯데리아 일때\n",
    "                    re_try = False\n",
    "                    restaurant.find_element_by_css_selector(\"div.col-sm-6.contract div.item.clearfix\").click()\n",
    "                    print(store_name, driver.current_url)\n",
    "                    url_find.append([store_name, store_address, driver.current_url])\n",
    "                    break\n",
    "                else :\n",
    "                    pass\n",
    "            if re_try == True:\n",
    "                print(\"실패\")\n",
    "                url_find.append([store_name,'획득실패'])\n",
    "        else :\n",
    "            pass\n",
    "\n",
    "    # 최종 url 정보는 url_find안에 담긴다.\n",
    "    driver.quit()\n",
    "    return url_find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address = [i for i in pd.read_csv(\"./data/lotteria/lotteria_data.csv\", index_col = 0)['매장주소']]\n",
    "# name = [i for i in pd.read_csv(\"./data/lotteria/lotteria_data.csv\", index_col = 0)['매장명']]\n",
    "# get_url_list = yogiyo_store_url_find(address, name, '롯데리아', 1)\n",
    "\n",
    "address = [i for i in pd.read_csv(\"./data/bugerking/bugerking_data.csv\", index_col = 0)['매장주소']]\n",
    "name = [i for i in pd.read_csv(\"./data/bugerking/bugerking_data.csv\", index_col = 0)['매장명']]\n",
    "get_url_list = yogiyo_store_url_find(address, name, '버거킹', 0)\n",
    "\n",
    "d_name = []\n",
    "d_address = []\n",
    "d_url = []\n",
    "\n",
    "for i in get_url_list:\n",
    "    if i[-1] == '획득실패':\n",
    "        d_name.append(i[0])\n",
    "        d_address.append('획득실패')\n",
    "        d_url.append('획득실패')\n",
    "    else :\n",
    "        d_name.append(i[0])\n",
    "        d_address.append(i[1])\n",
    "        d_url.append(i[2])\n",
    "    \n",
    "dict_t = {}\n",
    "dict_t['매장명'] = d_name\n",
    "dict_t['주소'] = d_address\n",
    "dict_t['url'] = d_url\n",
    "dict_a = pd.DataFrame(dict_t)\n",
    "# dict_a.to_csv('./data/lotteria/lotteria_urls.csv',encoding='utf-8-sig')\n",
    "dict_a.to_csv('./data/bugerking/bugerking_urls.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 습득한 요기요 매장별 상세페이지 주소 이용 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_get(url_list):\n",
    "    chromedriver = './python_ex_100/selenium/chromedriver'\n",
    "    first_days = [] # 크롤링 종료일 설정\n",
    "    store_dict = {}\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\")\n",
    "    browser =  webdriver.Chrome(chromedriver, options = options)\n",
    "    \n",
    "    for i in range(1,31,1): # 마지막 날짜(크롤링 시작 날짜) 20년 5월\n",
    "        first_days.append(\"2020년 5월 {}일\".format(i))\n",
    "    \n",
    "    try:\n",
    "        for url in url_list:\n",
    "            \n",
    "            browser.get(url)\n",
    "            browser.maximize_window()\n",
    "            time.sleep(1)\n",
    "            selected_store_name = browser.find_element_by_css_selector(\"div.restaurant-title > span\").text\n",
    "            print(selected_store_name)\n",
    "            \n",
    "            Interval = 0.5\n",
    "            time.sleep(Interval)\n",
    "\n",
    "            review_button = browser.find_elements_by_css_selector('.nav.nav-tabs.restaurant-tab a')\n",
    "            review_button[1].click()\n",
    "\n",
    "            # 화면 가장 아래로 스크롤 내리기\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "\n",
    "            # 현재 문서 높이를 가져와서 저장\n",
    "            prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            while True:\n",
    "                browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                try:\n",
    "                    more = browser.find_element_by_css_selector('li.list-group-item.btn-more a')\n",
    "                    more.click()\n",
    "                except:\n",
    "                    pass\n",
    "                time.sleep(Interval)\n",
    "\n",
    "                curr_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                if curr_height == prev_height:\n",
    "                    break\n",
    "\n",
    "                prev_height = curr_height\n",
    "\n",
    "                # first_day에 정한 날짜까지 스크롤할 시 스크롤 중지\n",
    "                if browser.find_elements_by_css_selector('li.list-group-item.star-point.ng-scope span.review-time.ng-binding')[-1].text.strip() in first_days:\n",
    "                    print(\"{}까지 스크롤 완료\".format(browser.find_elements_by_css_selector('li.list-group-item.star-point.ng-scope span.review-time.ng-binding')[-1].text.strip()))\n",
    "                    break\n",
    "\n",
    "\n",
    "            reviews = browser.find_elements_by_css_selector('li.list-group-item.star-point.ng-scope')\n",
    "\n",
    "            # 맛, 양, 배달 별 별점, 리뷰 리스트 선언\n",
    "            taste_ratings = []\n",
    "            quantity_ratings = []\n",
    "            delivery_ratings = []\n",
    "            overall_reviews = []\n",
    "            for i in reviews:\n",
    "                ratings = i.find_element_by_css_selector('li.list-group-item.star-point.ng-scope span.category')\n",
    "                taste_point = int(ratings.find_elements_by_css_selector('span')[-7].text)\n",
    "                quantity_point = int(ratings.find_elements_by_css_selector('span')[-4].text)\n",
    "                delivery_point = int(ratings.find_elements_by_css_selector('span')[-1].text)\n",
    "                if taste_point <= 3 or quantity_point <= 3 or delivery_point <= 3:\n",
    "                    taste_ratings.append(taste_point)\n",
    "                    quantity_ratings.append(quantity_point)\n",
    "                    delivery_ratings.append(delivery_point)\n",
    "                    overall_reviews.append(i.find_element_by_css_selector('p').text)\n",
    "\n",
    "            print('맛 평점: ', taste_ratings)\n",
    "            print('양 평점: ', quantity_ratings)\n",
    "            print('배달 평점: ', delivery_ratings)\n",
    "            print('전체', overall_reviews)\n",
    "\n",
    "            # 점포 별 별점리스트 및 리뷰 리스트 딕셔너리 선언\n",
    "            print(store_dict)\n",
    "            if store_dict == {}:\n",
    "                store_dict = {'taste':taste_ratings, 'quantity':quantity_ratings, 'delivery':delivery_ratings, 'reviews':overall_reviews, 'store_name':selected_store_name}\n",
    "                full_df = pd.DataFrame(store_dict)\n",
    "            else :\n",
    "                store_dict = {'taste':taste_ratings, 'quantity':quantity_ratings, 'delivery':delivery_ratings, 'reviews':overall_reviews, 'store_name':selected_store_name}\n",
    "                temp_dict = pd.DataFrame(store_dict)\n",
    "                full_df = pd.concat([full_df,temp_dict], ignore_index=True)\n",
    "            print(full_df)\n",
    "    except :\n",
    "        print(selected_store_name)\n",
    "        browser.quit()\n",
    "        return full_df\n",
    "    browser.quit()\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = 'lotteria/lotteria_urls'\n",
    "# result_name = 'lotteria'\n",
    "\n",
    "file_name = 'bugerking/bugerking_urls'\n",
    "result_name = 'bugerking'\n",
    "\n",
    "url_list = [i for i in pd.read_csv(\"./data/\"+file_name+\".csv\", index_col = 0)['url']]\n",
    "\n",
    "for n, i in enumerate(url_list):\n",
    "    print(n+1)\n",
    "    try:\n",
    "        if n == 0:\n",
    "            use_df = review_get2([i])\n",
    "        else :\n",
    "            use_df = pd.concat([use_df,review_get2([i])], ignore_index=True)\n",
    "            print(use_df.head())\n",
    "            print(use_df.tail())\n",
    "    except:\n",
    "        use_df.to_csv(\"./data/result/review_\"+result_name+\"_er.csv\",encoding='utf-8-sig')\n",
    "        # 오류 발생시 중간 저장후 종료.\n",
    "\n",
    "use_df.to_csv(\"./data/result/review_\"+result_name+\".csv\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링 후 빠진 매장 없는지 검사."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df = pd.read_csv(\"./data/result/review_\"+result_name+\".csv\",encoding='utf-8-sig')\n",
    "print(len(use_df.groupby(use_df['store_name']).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 API(Geocode)이용 위도, 경도 습득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_api(file_path):\n",
    "    client_id = '본인이 할당받은 ID 입력'\n",
    "    client_pw = '본인이 할당받은 Secret 입력'\n",
    "\n",
    "    api_url = 'https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode?query='\n",
    "\n",
    "    # 주소 목록 파일 (.csv)\n",
    "    \n",
    "    data = pd.read_csv(file_path, index_col = 0)\n",
    "    # 주소 목록 파일 (.xlsx)\n",
    "\n",
    "    # 네이버 지도 API 이용해서 위경도 찾기\n",
    "    geo_coordi = []     \n",
    "    for add in data['주소']:\n",
    "        add_urlenc = parse.quote(add)  \n",
    "        url = api_url + add_urlenc\n",
    "        request = Request(url)\n",
    "        request.add_header('X-NCP-APIGW-API-KEY-ID', client_id)\n",
    "        request.add_header('X-NCP-APIGW-API-KEY', client_pw)\n",
    "        try:\n",
    "            response = urlopen(request)\n",
    "        except HTTPError as e:\n",
    "            print('HTTP Error!')\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "        else:\n",
    "            rescode = response.getcode()\n",
    "            if rescode == 200:\n",
    "                response_body = response.read().decode('utf-8')\n",
    "                response_body = json.loads(response_body)   # json\n",
    "                if response_body['addresses'] == [] :\n",
    "                    print(\"'result' not exist!\")\n",
    "                    latitude = None\n",
    "                    longitude = None\n",
    "                else:\n",
    "                    latitude = response_body['addresses'][0]['y']\n",
    "                    longitude = response_body['addresses'][0]['x']\n",
    "                    print(\"Success!\")\n",
    "            else:\n",
    "                print('Response error code : %d' % rescode)\n",
    "                latitude = None\n",
    "                longitude = None\n",
    "\n",
    "        geo_coordi.append([latitude, longitude])\n",
    "\n",
    "\n",
    "    np_geo_coordi = np.array(geo_coordi)\n",
    "    pd_geo_coordi = pd.DataFrame({\"매장명\":data['매장명'].values, \"주소\": data['주소'].values,\n",
    "                                  \"위도\": np_geo_coordi[:, 0],\n",
    "                                  \"경도\": np_geo_coordi[:, 1]})\n",
    "    return pd_geo_coordi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"./data/lotteria/lotteria\"\n",
    "target = \"./data/bugerking/bugerking\"\n",
    "geo_df = geocode_api(target+\"_urls.csv\")\n",
    "geo_df.to_csv(target+\"_geo.csv\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도에 첨부할 바차트 생성.\n",
    "- import matplotlib.pyplot as plt\n",
    "- 함수 정의후 이용(바차트 이미지 image폴더에 저장)\n",
    "- \"브랜드명\"_geo2.csv 인 csv파일 생성(각 지점별 바차트 이미지 경로 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bar_chart(file_path, file_name, brand):\n",
    "    target = pd.read_csv(file_path+file_name+\".csv\", index_col = 0)\n",
    "    x_name = ['맛', '양', '배송']\n",
    "\n",
    "    for i in target.groupby(target['store_name']):\n",
    "        plt.rc('font', family='Malgun Gothic')\n",
    "        if brand == 0:\n",
    "            plt.bar(x_name, [i[1].mean()[0], i[1].mean()[1], i[1].mean()[2]], color=['darkorange', 'sandybrown', 'moccasin'], linestyle='dotted')\n",
    "            plt.title(i[0][4:])\n",
    "        elif brand == 1:\n",
    "            plt.bar(x_name, [i[1].mean()[0], i[1].mean()[1], i[1].mean()[2]], color=['red', 'maroon', 'firebrick'], linestyle='dotted')\n",
    "            plt.title(i[0][5:-1])\n",
    "        plt.ylim(1,5)\n",
    "        plt.text(x_name[0], i[1].mean()[0],i[1].mean()[0].round(2), fontsize = 12, horizontalalignment='center', verticalalignment='bottom')\n",
    "        plt.text(x_name[1], i[1].mean()[1],i[1].mean()[1].round(2), fontsize = 12, horizontalalignment='center', verticalalignment='bottom')\n",
    "        plt.text(x_name[2], i[1].mean()[2],i[1].mean()[2].round(2), fontsize = 12, horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "        if brand == 0:\n",
    "            plt.savefig(file_path+\"image/\"+i[0][4:]+\".png\")\n",
    "            plt.show()\n",
    "        elif brand == 1:\n",
    "            plt.savefig(file_path+\"image/\"+i[0][5:-1]+\".png\")\n",
    "            plt.show()\n",
    "    \n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브랜드 별 바차트 생성\n",
    "f_path = \"./data/lotteria/\"\n",
    "f_name = \"review_lotteria\"\n",
    "make_bar_chart(f_path, f_name, 1) # 롯데리아\n",
    "\n",
    "f_path = \"./data/bugerking/\"\n",
    "f_name = \"review_bugerking\"\n",
    "make_bar_chart(f_path, f_name, 0) # 버거킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀에 점포별 워드크라우드 경로, 바차트 경로 추가.\n",
    "def image_path_add(file_path, file_name):\n",
    "    locations = pd.read_csv(f_path+f_name[7:]+\"_geo.csv\", index_col = 0)\n",
    "    if 'bugerking' in f_name:\n",
    "        locations['wd_cloud'] = locations['매장명'].apply(lambda x:f_path+\"wordcloud/word_burgerking버거킹-\"+x+'.png')\n",
    "    elif 'lotteria' in f_name:\n",
    "        locations['wd_cloud'] = locations['매장명'].apply(lambda x:f_path+\"wordcloud/word_lotteria롯데리아-\"+x+'점.png')\n",
    "    locations['바_그래프'] = locations['매장명'].apply(lambda x:f_path+\"image/\"+x+'.png')\n",
    "    locations.to_csv(f_path+f_name[7:]+\"_geo2.csv\", encoding='utf-8-sig')\n",
    "    print(\"Create : \"+f_path+f_name[7:]+\"_geo2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀에 점포별 워드크라우드 경로, 바차트 경로 추가.\n",
    "f_path = \"./data/lotteria/\"\n",
    "f_name = \"review_lotteria\"\n",
    "image_path_add(f_path, f_name) # 롯데리아\n",
    "\n",
    "f_path = \"./data/bugerking/\"\n",
    "f_name = \"review_bugerking\"\n",
    "image_path_add(f_path, f_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도에 마커 찍고 이미지 첨부\n",
    "- !pip install folium\n",
    "- import folium\n",
    "- import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_map_create(file_path, file_name, brand):\n",
    "    store_infos = pd.read_csv(file_path+file_name, index_col = 0) # 파일 오픈\n",
    "    m = folium.Map(location=[37.503376,127.0475873],zoom_start=12) # 시작 위도 경도인것 같습다\n",
    "    for i in store_infos.values:\n",
    "        if brand == 0:\n",
    "            store_name = i[0]\n",
    "        elif brand == 1:\n",
    "            store_name = i[0]+'점'\n",
    "        pic1 = base64.b64encode(open(i[4],'rb').read()).decode() # 워드 클라우드 이미지 html에 올리기 위한 변환 과정입니다.\n",
    "        pic2 = base64.b64encode(open(i[5],'rb').read()).decode() # 바차트 이미지 html에 올리기 위한 변환 과정입니다.\n",
    "        image_tag = '<h1><p align=\"center\">'+store_name+'</p></h1><br><img src=\"data:image/jpeg;base64,{0}\"width=\"432\", height=\"288\"><br><br><img src=\"data:image/jpeg;base64,{1}\">'.format(pic1, pic2) # 이미지 추가\n",
    "        iframe = folium.IFrame(image_tag, width=450, height=750) # 마커 클릭시 창 크기 옵션인것 같습니다.\n",
    "        popup = folium.Popup(iframe, max_width=600) # 팝업창 크기?\n",
    "        folium.Marker([i[2], i[3]],popup=popup,tooltip=store_name).add_to(m) # 마커 추가입니다.\n",
    "        \n",
    "\n",
    "    m.save(file_path+file_name[:-9]+\"_info.html\") # 파일로 저정하는 부분입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc_f_path = \"./data/lotteria/\"\n",
    "bmc_f_name = \"lotteria_geo2.csv\"\n",
    "brand_map_create(bmc_f_path, bmc_f_name, 1) # 롯데리아\n",
    "\n",
    "bmc_f_path = \"./data/bugerking/\"\n",
    "bmc_f_name = \"bugerking_geo2.csv\"\n",
    "brand_map_create(bmc_f_path, bmc_f_name, 0) # 버거킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
