## [ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹]
---
### ëª©ì°¨
- [5.1 ê³„ì‚°ê·¸ë˜í”„](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#51-%EA%B3%84%EC%82%B0%EA%B7%B8%EB%9E%98%ED%94%84)
- [5.2 ì—°ì‡„ë²•ì¹™](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#52-%EC%97%B0%EC%87%84%EB%B2%95%EC%B9%99)
- [5.3 ì—­ì „íŒŒ](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#53-%EC%97%AD%EC%A0%84%ED%8C%8C)
- [5.4 ë‹¨ìˆœí•œ ê³„ì¸µ êµ¬í˜„í•˜ê¸°](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#54-%EB%8B%A8%EC%88%9C%ED%95%9C-%EA%B3%84%EC%B8%B5-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)
- [5.5 í™œì„±í™” í•¨ìˆ˜ ê³„ì¸µ êµ¬í˜„í•˜ê¸°](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#55-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98-%EA%B3%84%EC%B8%B5-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)
- [5.6 Affine/softmax ê³„ì¸µ êµ¬í˜„í•˜ê¸°](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#56-affinesoftmax-%EA%B3%84%EC%B8%B5-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)
---
#### CHAPTER5_ì˜¤ì°¨ì—­ì „íŒŒë²•
#### 2021_4_03~
---
#### 5.1 ê³„ì‚°ê·¸ë˜í”„
> ê³„ì‚° ê·¸ë˜í”„ëŠ” ê³„ì‚° ê³¼ì •ì„ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤.
> 
> ê·¸ë˜í”„ ìë£Œêµ¬ì¡°ë¡œ ë³µìˆ˜ì˜ ë…¸ë“œì™€ ì—£ì§€(edge, ë…¸ë“œì‚¬ì´ì˜ ì§ì„ )ë¡œ í‘œí˜„í•œë‹¤.
> 
#### 5.1.1 ê³„ì‚° ê·¸ë˜í”„ë¡œ í’€ë‹¤.
> ë¬¸ì œ 1 : ìŠˆí¼ì—ì„œ 1ê°œì— 100ì›ì¸ ì‚¬ê³¼ë¥¼ 2ê°œ ìƒ€ë‹¤. ì´ë•Œ ì§€ë¶ˆí•  ê¸ˆì•¡ì„ êµ¬í•˜ë¼(ì†Œë¹„ì„¸ëŠ” 10% ë¶€ê³¼)
> 
> ![5_1_ë¬¸ì œ1](./image/05/5_1_ë¬¸ì œ1.png)
> 
> ìœ„ì™€ ê°™ì´ 2ê°œì˜ ê·¸ë¦¼ì´ ìˆë‹¤. ì²«ë²ˆì§¸ ê·¸ë¦¼ì€ ì‚¬ê³¼ì˜ 100 ì›ì´ 'x2' ë…¸ë“œë¡œ íë¥´ê³  200ì›ì´ ë˜ì–´ ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬ëœë‹¤.
> 
> ê·¸ ë‹¤ìŒ 200ì›ì´ 'x1.1'ë…¸ë“œë¥¼ ê±°ì³ 220ì›ì´ ëœë‹¤. ë”°ë¼ì„œ ìµœì¢… ê¸ˆì•¡ì€ 220ì›ì´ ëœë‹¤.
> 
> ë‘ë²ˆì§¸ ê·¸ë¦¼ì€ ì²«ë²ˆì§¸ ê·¸ë¦¼ê³¼ ë‹¬ë¦¬ 'x'ë§Œì„ ì—°ì‚°ìœ¼ë¡œ ìƒê°í•œë‹¤. ì¦‰ 'ì‚¬ê³¼ì˜ ê°œìˆ˜'ì™€ 'ì†Œë¹„ì„¸'ê°€ ë³€ìˆ˜ë‹¤ ë˜ì–´ ì› ë°–ì— í‘œê¸°í•˜ê²Œ ëœë‹¤.
> 
> ë¬¸ì œ 2 : ìŠˆí¼ì—ì„œ ì‚¬ê³¼ 2ê°œ ê·¤ 3ê°œ êµ¬ë§¤í–ˆë‹¤ ì‚¬ê³¼ëŠ” ê°œë‹¹ 100ì› ê·¤ì€ 150ì›ì´ë‹¤. ì†Œë¹„ì„¸ê°€ 10%ì¼ë•Œ ì§€ë¶ˆ ê¸ˆì•¡ì„ êµ¬í•˜ë¼.
> 
> ![5_1_ë¬¸ì œ2](./image/05/5_1_ë¬¸ì œ2.png)
> 
> ìœ„ ê·¸ë¦¼ì—ì„  '+'ë¡œ í‘œê¸°ëœ ë§ì…ˆ ë…¸ë“œê°€ ìƒˆë¡œ ë“±ì¥í•œë‹¤.
> 
> ê³„ì‚°ê·¸ë˜í”„ëŠ” ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê³„ì‚°ì„ ì§„í–‰í•œë‹¤.
> 
> ë”°ë¼ì„œ ê²°ê³¼ëŠ” 715ì´ë‹¤.
> 
> ì§€ê¸ˆê¹Œì§€ ì‚´í´ë³¸ ë°”ë¡œ ê³„ì‚° ê·¸ë˜í”„ëŠ” ì•„ë˜ì™€ ê°™ì€ íë¦„ìœ¼ë¡œ ì§„í–‰ëœë‹¤.
> 
>> 1. ê³„ì‚° ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•œë‹¤.
>> 
>> 2. ê·¸ë˜í”„ì—ì„œ ê³„ì‚°ì„ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì§„í–‰í•œë‹¤.
> 
> ì—¬ê¸°ì„œ 2ë²ˆ í•­ëª©ì¸ 'ê·¸ë˜í”„ì—ì„œ ê³„ì‚°ì„ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì§„í–‰í•œë‹¤.'ì¸ ë‹¨ê³„ë¥¼ **ìˆœì „íŒŒ** ë¼ê³  í•œë‹¤.
> - ìˆœì „íŒŒëŠ” ê³„ì‚° ê·¸ë˜í”„ì˜ ì¶œë°œì  ë¶€í„° ì¢…ì°©ì ìœ¼ë¡œì˜ ì „íŒŒë‹¤.
> 
> - ìˆœì „íŒŒì˜ ë°˜ëŒ€ë°©í–¥(ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ)ì˜ ì „íŒŒëŠ” **ì—­ì „íŒŒ** ë¼ê³ í•˜ë©° ì—­ì „íŒŒëŠ” ë¯¸ë¶„ì„ ê³„ì‚°í•  ë•Œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.
> 
> #### 5.1.2 êµ­ì†Œì  ê³„ì‚° 
> ê³„ì‚° ê·¸ë˜í”„ì˜ íŠ¹ì§•ì€ 'êµ­ì†Œì  ê³„ì‚°'ì„ ì „íŒŒí•¨ìœ¼ë¡œì¨ ìµœì¢… ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤ëŠ” ì ì—ìˆë‹¤.
> - êµ­ì†Œì ì´ë€ 'ìì‹ ê³¼ ì§ì ‘ ê´€ê³„ëœ ì‘ì€ ë²”ìœ„'ë¼ëŠ” ëœ»ì´ë©° ì „ì²´ì—ì„œ ì–´ë–¤ ì¼ì´ ë²Œì–´ì§€ë“  ìƒê´€ì—†ì´ ìì‹ ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒ.
> 
>> ì—¬ëŸ¬ê°€ì§€ ìƒí’ˆì„ êµ¬ë§¤í•  ë•Œ ì‚¬ê³¼ 2ê°œë¥¼ í¬í•¨ í•˜ëŠ” ê²½ìš° ì—¬ëŸ¬ ì‹í’ˆì„ êµ¬ë§¤(ë³µì¡í•œ ì—¬ëŸ¬ ê°€ì§€ ê³„ì‚°)í•˜ì—¬ ê¸ˆì•¡ì´ 6,000ì›ì´ ë˜ì—ˆë‹¤.
>> 
>> í•´ë‹¹ ê¸ˆì•¡ì— ì‚¬ê³¼ 2ê°œì˜ ê¸ˆì•¡ì„ ì¶”ê°€í•˜ëŠ” ê³„ì‚°(6000 + 200)ì€ 6000ì´ë¼ëŠ” ê¸ˆì•¡ì´ ì–´ë–¤ ê³„ì‚°ì„ í†µí•´ ë‚˜ì™“ëŠ”ì§€ ìƒê´€ ì—†ì´ ë‘ ìˆ«ì(6000, 200)ë¥¼ ë”í•˜ë©´ ëœë‹¤ëŠ” ê²ƒì´ë‹¤.
>> 
>> ê° ë…¸ë“œëŠ” ìì‹ ê³¼ ê´€ë ¨ëœ ê³„ì‚° ì´ì™¸ì—ëŠ” ì•„ë¬´ ì‹ ê²½ì“¸ í•„ìš”ê°€ ì—†ë‹¤.
>
> ì´ì™€ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ëŠ” êµ­ì†Œì  ê³„ì‚°ì— ì§‘ì¤‘í•œë‹¤.
> 
> ì „ì²´ ê³„ì‚°ì´ ì•„ë¬´ë¦¬ ë³µí•©í•˜ë”ë¼ë„ ê° ë‹¨ê³„ì—ì„œ í•˜ëŠ” ì¼ì€ í•´ë‹¹ ë…¸ë“œì˜ êµ­ì†Œì  ê³„ì‚°ì´ë‹¤.
> - êµ­ì†Œì  ê³„ì‚°ì€ ê°„ë‹¨í•˜ì§€ë§Œ ê·¸ ê²°ê³¼ë¥¼ ì „ë‹¬ í•¨ìœ¼ë¡œì¨ ì „ì²´ë¥¼ êµ¬ì„±í•˜ëŠ” ë³µì¡í•œ ê³„ì‚°ì„ í•´ë‚¼ ìˆ˜ ìˆë‹¤.
> 
> #### 5.1.3 ì™œ ê³„ì‚° ê·¸ë˜í”„ë¡œ í‘¸ëŠ”ê°€?
> ê³„ì‚°ê·¸ë˜í”„ì˜ ì´ì ì€ êµ­ì†Œì  ê³„ì‚° ë•Œë¬¸ì´ë‹¤.
> - ì „ì²´ê°€ ì•„ë¬´ë¦¬ ë³µì¡í•´ë„ ê° ë…¸ë“œì—ì„  ë‹¨ìˆœí•œ ê³„ì‚°ì— ì§‘ì¤‘í•´ ë¬¸ì œë¥¼ ë‹¨ìˆœí™” í•  ìˆ˜ ìˆê¸° ë•Œë¬¸
> 
> ë˜í•œ ê³„ì‚° ê·¸ë˜í”„ëŠ” ì¤‘ê°„ ê³„ì‚° ê²°ê³¼ë¥¼ ëª¨ë‘ ë³´ê´€í•  ìˆ˜ ìˆë‹¤.
> - ex. ì‚¬ê³¼ 2ê°œ ê¹Œì§€ ê³„ì‚° í–ˆì„ëŒ€ ê¸ˆì•¡ = 200, ì†Œë¹„ì„¸ë¥¼ ë”í•˜ê¸° ì „ì˜ ê¸ˆì•¡ = 650
> 
> ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ í° ì´ìœ ëŠ” '**ì—­ì „íŒŒë¥¼ í†µí•´ ë¯¸ë¶„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚° í•  ìˆ˜ ìˆë‹¤**'ëŠ” ì ì— ìˆë‹¤.
> 
> ![ì—­ì „íŒŒì—_ì˜í•œ_ë¯¸ë¶„_ê°’ì˜_ì „ë‹¬](./image/05/ì—­ì „íŒŒì—_ì˜í•œ_ë¯¸ë¶„_ê°’ì˜_ì „ë‹¬.png)
> 
> ê²°ê³¼ë§Œ ë‚˜íƒ€ë‚¸ë‹¤ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ ìƒì˜ ì—­ì „íŒŒì— ì˜í•´ ë¯¸ë¶„ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.
> 
> ìœ„ ê·¸ë¦¼ì˜ ë¹¨ê°„ ì„ ê³¼ ê°™ì´ ì—­ì „íŒŒëŠ” ìˆœì „íŒŒì™€ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ í˜ëŸ¬ê°„ë‹¤. ì´ ì „íŒŒëŠ” 'êµ­ì†Œì  ë¯¸ë¶„'ì„ ì „ë‹¬í•˜ê³  ê·¸ ë¯¸ë¶„ ê°’ì€ í™”ì‚´í‘œ ì•„ë˜ ì ëŠ”ë‹¤.
>> ìœ„ ì˜ˆì—ì„œ ì—­ì „íŒŒëŠ” ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ '1 â†’ 1.1 â†’ 2.2' ìˆœìœ¼ë¡œ ë¯¸ë¶„ ê°’ì„ ì „ë‹¬í•œë‹¤.
>>
>> ì´ ê²°ê³¼ë¡œ ë¶€í„° ì‚¬ê³¼ ê°€ê²©ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„ ê°’ì€ 2.2 ë¼ í•  ìˆ˜ ìˆë‹¤.
>> 
>> ì‚¬ê³¼ê°€ 1ì› ì˜¤ë¥´ë©´ ìµœì¢… ê¸ˆì•¡ì€ 2.2ì› ì˜¤ë¥¸ë‹¤ëŠ” ëœ»(ì •í™•íŒ ì‚¬ê³¼ ê°’ì´ ì•„ì£¼ ì¡°ê¸ˆ ì˜¤ë¥´ë©´ ìµœì¢… ê¸ˆì•¡ì€ ì•„ì£¼ ì‘ì€ ê°’ì˜ 2.2ë°° ë§Œí¼ ì˜¤ë¥¸ë‹¤.)
> 
> ìœ„ ì˜ˆì—ì„  ì‚¬ê³¼ ê°€ê²©ì— ëŒ€í•œ ë¯¸ë¶„ë§Œ êµ¬í–ˆì§€ë§Œ **ì†Œë¹„ì„¸ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„**, **ì‚¬ê³¼ ê°œìˆ˜ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„** ë˜í•œ ê°™ì€ ìˆœì„œë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.
> 
> ë˜í•œ ì¤‘ê°„ê¹Œì§€ êµ¬í•œ ë¯¸ë¶„ ê²°ê³¼ë¥¼ ê³µìœ í•  ìˆ˜ ìˆì–´ì„œ ë‹¤ìˆ˜ì˜ ë¯¸ë¶„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
> 
> ì´ì™€ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ì˜ ì´ì ì€ ìˆœì „íŒŒì™€ ì—­ì „íŒŒë¥¼ í™œìš©í•´ ê°ë³€ìˆ˜ì˜ ë¯¸ë¶„ì„ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.
> 
> #### 5.2 ì—°ì‡„ë²•ì¹™
> êµ­ì†Œì  ë¯¸ë¶„ì„ ì „ë‹¬í•˜ëŠ” ì›ë¦¬ëŠ” **ì—°ì‡„ë²•ì¹™**ì— ë”°ë¥¸ ê²ƒì´ë‹¤.
> 
> #### 5.2.1 ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒ
> y = f(x)ë¼ëŠ” ê³„ì‚°ì˜ ì—­ì „íŒŒë¥¼ ì•„ë˜ì™€ ê°™ì´ ê·¸ë ¸ë‹¤.
> 
> ![ê³„ì‚°_ê·¸ë˜í”„ì˜_ì—­ì „íŒŒ_1](./image/05/ê³„ì‚°_ê·¸ë˜í”„ì˜_ì—­ì „íŒŒ_1.png)
> 
> ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ì—­ì „íŒŒì˜ ê³„ì‚° ì ˆì°¨ëŠ” ì‹ í˜¸ Eì— ë…¸ë“œì˜ êµ­ì†Œì  ë¯¸ë¶„ì„ ê³±í•œ í›„ ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ë‹¤.
> - ì—¬ê¸°ì„œ ë§í•˜ëŠ” êµ­ì†Œì  ë¯¸ë¶„ì€ ìˆœì „íŒŒ ë•Œì˜ y = f(x)ê³„ì‚°ì˜ ë¯¸ë¶„ì„ êµ¬í•œë‹¤ëŠ” ê²ƒ.(xì— ëŒ€í•œ yì˜ ë¯¸ë¶„)
> 
>> y = f(x) = x^2 ì´ë¼ë©´ êµ­ì†Œì  ë¯¸ë¶„ = 2xê°€ ëœë‹¤. ê·¸ë¦¬ê³  êµ­ì†Œì ì¸ ë¯¸ë¶„ì„ ìƒë¥˜ì—ì„œ ì „ë‹¬ëœ ê°’(ì—¬ê¸°ì„  E)ì— ê³±í•´ ì•ìª½ ë…¸ë“œë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ë‹¤.
>
> #### 5.2.2 ì—°ì‡„ë²•ì¹™ì´ë€?
> ì—°ì‡„ë²•ì¹™ì„ ì„¤ëª…í•˜ê¸° ì „ í•©ì„±í•¨ìˆ˜ ë¶€í„° ì‹œì‘í•œë‹¤.
> 
> ![í•©ì„±í•¨ìˆ˜](./image/05/í•©ì„±í•¨ìˆ˜.png)
> 
> ì—°ì‡„ë²•ì¹™ì€ í•©ì„± í•¨ìˆ˜ì˜ ë¯¸ë¶„ì— ëŒ€í•œ ì„±ì§ˆì´ë©° ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤.
> 
> **í•©ì„± í•¨ìˆ˜ì˜ ë¯¸ë¶„ì€ í•©ì„± í•¨ìˆ˜ë¥¼ êµ¬ì„±í•˜ëŠ” ê° í•¨ìˆ˜ì˜ ë¯¸ë¶„ì˜ ê³±ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤**.
> 
> ì´ê²ƒì´ ì—°ì‡„ë²•ì¹™ì˜ ì›ë¦¬ë‹¤.
> 
> ìœ„ì˜ ì‹ì„ ì˜ˆë¡œ ì„¤ëª…í•œë‹¤. 
> 
> ![ì—°ì‡„ë²•ì¹™_1](./image/05/ì—°ì‡„ë²•ì¹™_1.png)
> 
> #### 5.2.3 ì—°ì‡„ë²•ì¹™ê³¼ ê³„ì‚° ê·¸ë˜í”„
> ìœ„ ì—°ì‡„ë²•ì¹™ ê³„ì‚°ì„ ê³„ì‚°ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³¸ë‹¤. 2ì œê³± ê³„ì‚°ì„ ```**2```ë…¸ë“œë¡œ ë‚˜íƒ€ë‚´ë©´ ì•„ë˜ì™€ ê°™ì´ ê·¸ë¦´ ìˆ˜ ìˆë‹¤. **
> 
> ![ì—°ì‡„ë²•ì¹™_ê³„ì‚°ê·¸ë˜í”„_1](./image/05/ì—°ì‡„ë²•ì¹™_ê³„ì‚°ê·¸ë˜í”„_1.png)
>
> ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒëŠ” ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ì¡±ìœ¼ë¡œ ì‹ í˜¸ë¥¼ ì „íŒŒí•œë‹¤. ì—­ì „íŒŒì˜ ê³„ì‚° ì ˆì°¨ì—ì„œëŠ” ë…¸ë“œë¡œ ë“¤ì–´ì˜¨ ì…ë ¥ ì‹ í˜¸ì— ê·¸ ë…¸ë“œì˜ êµ­ì†Œì  ë¯¸ë¶„(í¸ë¯¸ë¶„)ì„ ê³±í•œ í›„ ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬í•œë‹¤.
> 
> ì˜ˆë¥¼ë“¤ì–´ ```**2``` ë…¸ë“œì—ì„œ ì—­ì „íŒŒë¥¼ ë³¸ë‹¤.
> 
> ![ì—°ì‡„ë²•ì¹™_ê³„ì‚°ê·¸ë˜í”„_2](./image/05/ì—°ì‡„ë²•ì¹™_ê³„ì‚°ê·¸ë˜í”„_2.png)
>
> #### 5.3 ì—­ì „íŒŒ
> ì§€ê¸ˆê¹Œì§„ ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒê°€ ì—°ì‡„ë²•ì¹™ì— ë”°ë¼ ì§„í–‰ë˜ëŠ” ëª¨ìŠµì„ ì„¤ëª…í–ˆë‹¤.
> - ì´ì œë¶€í„´ +, Xë“±ì˜ ì—°ì‚°ì„ ì˜ˆë¡œ ë“¤ì–´ ì—­ì „íŒŒì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•œë‹¤.
>
> #### 5.3.1. ë§ì…ˆ ë…¸ë“œì˜ ì—­ì „íŒŒ
> ì—¬ê¸°ì„  z = x+yë¼ëŠ” ì‹ì„ ëŒ€í•­ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ ì‚´í´ë³¸ë‹¤.
> 
> z=x+yì˜ ë¯¸ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì´ í•´ì„ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
> 
> ![ë§ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_1](./image/05/ë§ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_1.png)
> 
> ![ë§ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_2](./image/05/ë§ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_2.png)
> 
> #### 5.3.2 ê³±ì…ˆ ë…¸ë“œì˜ ì—­ì „íŒŒ
> ê³±ì…ˆ ë…¸ë“œì˜ ì—­ì „íŒŒëŠ” z = xyë¼ëŠ” ì‹ì„ ì˜ˆë¡œ ë“ ë‹¤.
> - ì´ ì‹ì˜ ë¯¸ë¶„ì€ ì•„ë˜ê·¸ë¦¼ê³¼ ê°™ë‹¤.
> 
> ![ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_1](./image/05/ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_1.png)
> 
> ìœ„ ì‹ì„ ì´ìš©í•´ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ ì•„ë˜ì™€ ê°™ì´ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.
> - ì™¼ìª½ : ìˆœì „íŒŒ, ì˜¤ë¥¸ìª½ : ì—­ì „íŒŒ
> 
> ![ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_2](./image/05/ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_2.png)
> 
> ê³±ì…ˆ ë…¸ë“œ ì—­ì „íŒŒëŠ” ìƒë¥˜ì˜ ê°’ì— ìˆœì „íŒŒ ë•Œì˜ ì…ë ¥ ì‹ í˜¸ë“¤ì„ '**ì„œë¡œ ë°”ê¾¼ê°’**'ì„ ê³±í•´ í•˜ë¥˜ë¡œ ë³´ë‚¸ë‹¤.
> 
> - ì„œë¡œ ë°”ê¾¼ ê°’ì´ë€ ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ìˆœì „íŒŒ ë•Œ xì˜€ë‹¤ë©´ ì—­ì „íŒŒ ë•ŒëŠ” y, ìˆœì „íŒŒ ë•Œ yì˜€ë‹¤ë©´ ì—­ì „íŒŒ ë•Œ xë¡œ ë°”ê¾¼ë‹¤ëŠ” ê²ƒì´ë‹¤.
> 
> 10 x 5 = 50 ì´ë¼ëŠ” ê³„ì‚°ì„ êµ¬ì²´ì ì¸ ì˜ˆë¡œ ë“¤ì–´ ì„¤ëª…í•œë‹¤.
> - ì—­ì „íŒŒ ë•Œ ìƒë¥˜ì—ì„œ 1.3 ê°’ì´ í˜ëŸ¬ë‚˜ì˜¨ë‹¤.
> 
> ![ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_3](./image/05/ê³±ì…ˆ_ë…¸ë“œì˜_ì—­ì „íŒŒ_3.png)
> 
> ê³±ì…ˆì˜ ì—­ì „íŒŒëŠ” ì…ë ¥ ì‹ í˜¸ë¥¼ ë°”ê¾¼ ê°’ì„ ê³±í•œë‹¤.
> - í•˜ë‚˜ëŠ” 13 í•˜ë‚˜ëŠ” 6.5
> 
> ê³±ì…ˆì˜ ì—­ì „íŒŒëŠ” ë§ì…ˆì˜ ì—­ì „íŒŒì™€ ë‹¬ë¦¬ ìˆœë°©í–¥ ì…ë ¥ ì‹ í˜¸ì˜ ê°’ì´ í•„ìš”í•˜ë‹¤.
> - ê³±ì…ˆ ë…¸ë“œë¥¼ êµ¬í˜„í•  ë•Œ ìˆœì „íŒŒì˜ ì…ë ¥ ì‹ í˜¸ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•´ë‘”ë‹¤.
> 
> #### 5.3.3 ì‚¬ê³¼ ì‡¼í•‘ì˜ ì˜ˆ
> ì´ ë¬¸ì œì—ì„  ì‚¬ê³¼ì˜ ê°€ê²©, ì‚¬ê³¼ì˜ ê°œìˆ˜, ì†Œë¹„ì„¸ë¼ëŠ” ì„¸ ë³€ìˆ˜ ê°ê°ì´ ìµœì¢… ê¸ˆì•¡ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ì£¼ëŠëƒ í’€ì–´ë³¸ë‹¤.
> - ì‚¬ê³¼ ê°€ê²©ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„, ì‚¬ê³¼ ê°œìˆ˜ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„, ì†Œë¹„ì„¸ì— ëŒ€í•œ ì§€ë¶ˆ ê¸ˆì•¡ì˜ ë¯¸ë¶„ì„ êµ¬í•˜ëŠ” ê²ƒì— í•´ë‹¹.
> 
> ì´ë¥¼ ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒë¥¼ ì‚¬ìš©í•´ í’€ë©´ ì•„ë˜ì™€ ê°™ë‹¤.
> 
> ![ì‚¬ê³¼_ì‡¼í•‘_ì—­ì „íŒŒ](./image/05/ì‚¬ê³¼_ì‡¼í•‘_ì—­ì „íŒŒ.png)
> 
> ìœ„ ê·¸ë¦¼ì„ í†µí•´ ì‚¬ê³¼ ê°€ê²©ì˜ ë¯¸ë¶„, ì‚¬ê³¼ ê°œìˆ˜ì˜ ë¯¸ë¶„, ì†Œë¹„ì„¸ì˜ ë¯¸ë¶„ì„ êµ¬í•˜ì˜€ë‹¤.
> - ì†Œë¹„ì„¸ì™€ ì‚¬ê³¼ ê°€ê²©ì´ ê°™ì€ ì–‘ë§Œí¼ ì¦ê°€í•œë‹¤ë©´ ìµœì¢… ê¸ˆì•¡ì—ì„œëŠ” ì†Œë¹„ì„¸ê°€ 200ì˜ í¬ê¸°, ì‚¬ê³¼ ê°€ê²©ì´ 2,2ì˜ í¬ê¸°ë¡œ ì˜í–¥ì„ ì¤€ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤.(ì†Œë¹„ì„¸ 1ì€ 100%, ì‚¬ê³¼ ê°€ê²© 1ì€ 1ì›)
> 
> #### 5.4 ë‹¨ìˆœí•œ ê³„ì¸µ êµ¬í˜„í•˜ê¸°
> - ì‹ ê²½ë§ì„ êµ¬ì„±í•˜ëŠ” 'ê³„ì¸µ'ê°ê°ì„ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œ êµ¬í˜„, 'ê³„ì¸µ'ì´ë€ ì‹ ê²½ë§ì˜ ê¸°ëŠ¥ ë‹¨ìœ„
> 
> ì‚¬ê³¼ ì‡¼í•‘ì˜ ì˜ˆë¥¼ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•œë‹¤.
> - ê³±ì…ˆ ë…¸ë“œ : MulLayer , ë§ì…ˆ ë…¸ë“œ : AddLayer
> 
> #### 5.4.1 ê³±ì…ˆ ê³„ì¸µ
> ëª¨ë“  ê³„ì¸µì€ forward()ì™€ backward()ë¼ëŠ” ê³µí†µì˜ ë©”ì„œë“œ(ì¸í„°í˜ì´ìŠ¤)ë¥¼ ê°–ë„ë¡ êµ¬í˜„í•  ê²ƒì´ë‹¤.
> - forward()ëŠ” ìˆœì „íŒŒ,.backward()ëŠ” ì—­ì „íŒŒë¥¼ ì²˜ë¦¬
> 
> ê³±ì…ˆ ê³„ì¸µì„ ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í•œë‹¤.
> ```Python
> class MulLayer:
>     def __init__(self):
>         self.x = None
>         self.y = None
>     
>     def forward(self, x, y):
>         self.x = x
>         self.y = y
>         out = x * y
>         
>         return out
>         
>     def backward(self, dout):
>         dx = dout * self.y # xì™€ yìŠ¤ì™‘
>         dy = dout * self.x
>         
>         return dx, dy
> ```
> __init__()ì—ì„  ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì¸ xì™€ yë¥¼ ì´ˆê¸°í™” í•œë‹¤.
> - ì´ ë‘ ë³€ìˆ˜ëŠ” ìˆœì „íŒŒ ì‹œì˜ ì…ë ¥ ê°’ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.
> 
> forward()ì—ì„œëŠ” xì™€ yë¥¼ ì¸ìˆ˜ë¡œ ë°›ê³  ë‘ ê°’ì„ ê³±í•´ì„œ ë°˜í™˜í•œë‹¤.
> 
> backward()ì—ì„œëŠ” ìƒë¥˜ì—ì„œ ë„˜ì–´ì˜¨ ë¯¸ë¶„(dout)ì— ìˆœì „íŒŒ ë•Œì˜ ê°’ì„ 'ì„œë¡œ ë°”ê¿”'ê³±í•œ í›„ í•˜ë¥˜ë¡œ í˜ë¦°ë‹¤.
> 
> ì´ì œ MulLayerë¥¼ ì‚¬ìš©í•´ ì‚¬ê³¼ ì‡¼í•‘ì„ êµ¬í˜„í•´ë³¸ë‹¤.
> ```Python
> apple = 100
> apple_num = 2
> tax = 1.1
> 
> # ê³„ì¸µë“¤
> mul_apple_layer = MulLayer()
> mul_tax_layer = MulLayer()
> 
> # ìˆœì „íŒŒ
> apple_price = mul_apple_layer.forward(apple, apple_num)
> price = mul_apple_layer.forward(apple_price, tax)
> 
> print(price) # 220
> 
> # ì—­ì „íŒŒ
> dprice=1
> dapple_price, dtax = mul_tax_layer(dprice)
> dapple, dapple_num = mul_apple_layer(dapple_price)
> 
> print(dapple, dapple_num, dtax) # 2.2 110 200
> ```
> backward() í˜¸ì¶œ ìˆœì„œëŠ” forward()ì™€ëŠ” ë°˜ëŒ€ë‹¤. ë˜ backward()ê°€ ë°›ëŠ” ì¸ìˆ˜ëŠ” 'ìˆœì „íŒŒì˜ ì¶œë ¥ì— ëŒ€í•œ ë¯¸ë¶„'ì„ì— ì£¼ì˜ í•´ì•¼í•œë‹¤.
> - mul_apple_layerë¼ëŠ” ê³±ì…ˆ ê³„ì¸µì€ ìˆœì „íŒŒ ë•Œ apple_priceë¥¼ ì¶œë ¥í•˜ì§€ë§Œ ì—­ì „íŒŒ ë•ŒëŠ” apple_priceì˜ ë¯¸ë¶„ê°’ì¸ dapple_priceë¥¼ ì¸ìˆ˜ë¡œ ë°›ëŠ”ë‹¤.
> 
> ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ëŠ” ì•„ë˜ ê·¸ë¦¼ì˜ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
> 
> ![ì‚¬ê³¼_ì‡¼í•‘_ì—­ì „íŒŒ](./image/05/ì‚¬ê³¼_ì‡¼í•‘_ì—­ì „íŒŒ.png)
>
> #### 5.4.2 ë§ì…ˆ ê³„ì¸µ
> ```Python
> class AddLayer:
>     def __init__(self):
>         pass
> 
>     def forward(self, x, y):
>         out = x + y
> 
>         return out
> 
>     def backward(self, dout):
>         dx = dout * 1
>         dy = dout * 1
> 
>         return dx, dy
> ```
> ë§ì…ˆ ê³„ì¸µì—ëŠ” ì´ˆê¸°í™”ê°€ í•„ìš”ì—†ë‹¤
> - __init__()ì—ì„œ ì•„ë¬´ì¼ë„ í•˜ì§€ ì•ŠëŠ”ë‹¤.
> 
> ë§ì…ˆ ê³„ì¸µì˜ forward()ì—ì„œëŠ” ì…ë ¥ë°›ì€ ë‘ ì¸ìˆ˜ x, yë¥¼ ë”í•´ì„œ ë°˜í™˜í•œë‹¤.
> 
> backward()ì—ì„œëŠ” ìƒë¥˜ì—ì„œ ë‚´ë ¤ì˜¨ ë¯¸ë¶„(dout)ì„ ê·¸ëŒ€ë¡œ í•˜ë¥˜ë¡œ ì „ë‹¬í•œë‹¤.
> 
> ë§ì…ˆ ê³„ì¸µê³¼ ê³±ì…ˆ ê³„ì¸µì„ ì‚¬ìš©í•´ ì‚¬ê³¼ 2ê°œì™€ ê·¤ 3ê°œë¥¼ ì‚¬ëŠ” ìƒí™©ì„ êµ¬í˜„í•œë‹¤.
> 
> ![ì‚¬ê³¼_ê·¤_ì—­ì „íŒŒ](./image/05/ì‚¬ê³¼_ê·¤_ì—­ì „íŒŒ.png)
> 
> ```Python
> apple = 100
> apple_num = 2
> orange = 150
> orange_num = 3
> tax = 1.1
> 
> # layer
> mul_apple_layer = MulLayer()
> mul_orange_layer = MulLayer()
> add_apple_orange_layer = AddLayer()
> mul_tax_layer = MulLayer()
> 
> # forward
> apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)
> orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)
> all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)
> price = mul_tax_layer.forward(all_price, tax)  # (4)
> 
> # backward
> dprice = 1
> dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)
> dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)
> dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)
> dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)
> 
> print(price) # 715
> print(dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650
> ```
> ì½”ë“œê°€ ê¸¸ì–´ì¡Œì§€ë§Œ ê°ê°ì˜ ëª…ë ¹ì€ ë‹¨ìˆœí•˜ë‹¤.
> 
> í•„ìš”í•œ ê³„ì¸µì„ ë§Œë“¤ì–´ ìˆœì „íŒŒ ë©”ì„œë“œì¸ forward()ë¥¼ ì ì ˆí•œ ìˆœì„œë¡œ í˜¸ì¶œí•œë‹¤
> 
> ê·¸ ë‹¤ìŒ ìˆœì „íŒŒì™€ ë°˜ëŒ€ ìˆœì„œë¡œ ì—­ì „íŒŒ ë©”ì„œë“œì¸ backward()ë¥¼ í˜¸ì¶œí•˜ë©´ ì›í•˜ëŠ” ë¯¸ë¶„ì´ ë‚˜ì˜¨ë‹¤.
> 
> ì´ì™€ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ì—ì„œ ê³„ì¸µì€ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìœ¼ë©° ì´ë¥¼ ì‚¬ìš©í•´ ë³µì¡í•œ ë¯¸ë¶„ë„ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
> 
> #### 5.5 í™œì„±í™” í•¨ìˆ˜ ê³„ì¸µ êµ¬í˜„í•˜ê¸°
> ì‹ ê²½ë§ì„ êµ¬ì„±í•˜ëŠ” ì¸µ(ê³„ì¸µ) ê°ê°ì„ í´ë˜ìŠ¤ í•˜ë‚˜ë¡œ êµ¬í˜„í•œë‹¤.
> - ìš°ì„  í™œì„±í™” í•¨ìˆ˜ì¸ ReLUì™€ Sigmoid ê³„ì¸µì„ êµ¬í˜„í•œë‹¤.
> 
> #### 5.5.1 ReLUê³„ì¸µ
> í™œì„±í™” í•¨ìˆ˜ë¡œ ì‚¬ìš©ë˜ëŠ” ReLUì˜ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
> 
> ![ReLU_ìˆ˜ì‹](./image/05/ReLU_ìˆ˜ì‹.png)
> 
> ìœ„ ì‹ì—ì„œ xì— ëŒ€í•œ yì˜ ë¯¸ë¶„ì€ ì•„ë˜ ì‹ê³¼ ê°™ì´ êµ¬í•œë‹¤.
> 
> ![ReLU_ë¯¸ë¶„](./image/05/ReLU_ë¯¸ë¶„.png)
> 
> ìœ„ ì‹ ì—ì„œì™€ ê°™ì´ ìˆœì „íŒŒ ë•Œì˜ ì…ë ¥ì¸ xê°€ 0ë³´ë‹¤ í¬ë©´ ì—­ì „íŒŒëŠ” ìƒë¥˜ì˜ ê°’ì„ ê·¸ëŒ€ë¡œ í•˜ë¥˜ë¡œ í˜ë¦°ë‹¤.
> 
> ë°˜ë©´ ìˆœì „íŒŒ ë•Œ xê°€ 0ì´í•˜ë©´ ì—­ì „íŒŒ ë•ŒëŠ” í•˜ë¥˜ë¡œ ì‹ í˜¸ë¥¼ ë³´ë‚´ì§€ ì•ŠëŠ”ë‹¤.(0ì„ ë³´ë‚¸ë‹¤.)
> 
> ê³„ì‚° ê·¸ë˜í”„ë¡œ ê·¸ë¦¬ë©´ ì•„ë˜ì™€ ê°™ì´ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.
> 
> ![ReLU_ê³„ì‚°_ê·¸ë˜í”„](./image/05/ReLU_ê³„ì‚°_ê·¸ë˜í”„.png)
> 
> ì´ì œ ReLUê³„ì¸µì„ êµ¬í˜„í•œë‹¤.
> - ì‹ ê²½ë§ ê³„ì¸µì˜ forward(), backward()í•¨ìˆ˜ëŠ” ë„˜íŒŒì´ ë°°ì—´ì„ ì¸ìˆ˜ë¡œ ë°›ëŠ”ë‹¤ê³  ê°€í•œë‹¤.
> ```Python
> class Relu:
>     def __init__(self):
>         self.mask = None
> 
>     def forward(self, x):
>         self.mask = (x <= 0)
>         out = x.copy()
>         out[self.mask] = 0
> 
>         return out
> 
>     def backward(self, dout):
>         dout[self.mask] = 0
>         dx = dout
> 
>         return dx
> ```
> ReLUí´ë˜ìŠ¤ëŠ” maskë¼ëŠ” ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¥¼ ê°€ì§„ë‹¤.
> - maskëŠ” True/Falseë¡œ êµ¬ì„±ëœ ë„˜íŒŒì´ ë°°ì—´ë¡œ ìˆœì „íŒŒì˜ ì…ë ¥ì¸ xì˜ ì›ì†Œ ê°’ì´ 0ì´í•˜ì¸ ì¸ë±ìŠ¤ëŠ” True, ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” Falseë¡œ ìœ ì§€í•œë‹¤
> 
> mask ë³€ìˆ˜ëŠ” ì•„ë˜ì˜ ì˜ˆì™€ ê°™ì´ True/Falseë¡œ êµ¬ì„±ëœ ë„˜íŒŒì´ ë°°ì—´ì„ ìœ ì§€í•œë‹¤.
> ```Python
> x = np.array( [[1.0, -0.5], [-2.0, 3.0]] )
> mask = (x <= 0)
> print(mask)
> '''
> [[False  True]
>  [ True False]]
> '''
> ```
> ìœ„ì™€ ê°™ì´ ìˆœì „íŒŒ ë•Œì˜ ì…ë ¥ì´ 0ì´í•˜ë©´ ì—­ì „íŒŒ ë•Œì˜ ê°’ì€ 0ì´ ë¼ì–´ì•¼ í•œë‹¤.
> 
> ê·¸ë˜ì„œ ì—­ì „íŒŒ ë•ŒëŠ” ìˆœì „íŒŒ ë•Œ ë§Œë“¤ì–´ë‘” maskë¥¼ ì‚¬ìš©í•´ ì›ì†Œê°€ Trueì¸ ê³³ì—ì„œëŠ” ìƒë¥˜ì—ì„œ ì „íŒŒëœ doutë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•œë‹¤.
> 
> #### 5.5.2 Sigmoid ê³„ì¸µ
> ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ëŠ” ë‹¤ìŒ ì‹ì„ ì˜ë¯¸í•˜ëŠ” í•¨ìˆ˜ë‹¤.
> 
> ![ì‹œê·¸ëª¨ì´ë“œ_ì‹](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ì‹.png)
> 
> ì´ ì‹ì„ ê³„ì‚° ê·¸ë˜í”„ë¡œ ê·¸ë¦¬ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤.
> 
> ![ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µì˜ ê³„ì‚°_ê·¸ë˜í”„](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„.png)
> 
> ìœ„ ê³„ì‚° ê·¸ë˜í”„ì—ì„  'x'ì™€ '+'ë…¸ë“œ ë¿ ì•„ë‹ˆë¼ 'exp', '/'ë…¸ë“œê°€ ì¶”ê°€ ë˜ì—ˆë‹¤.
> - exp ë…¸ë“œ : y = exp(x) ê³„ì‚° ìˆ˜í–‰, / ë…¸ë“œ : y = 1/x ê³„ì‚° ìˆ˜í–‰
>
> ìœ„ ê³„ì‚° ê·¸ë˜í”„ì™€ ê°™ì´ ìœ„ì˜ ì‹ì˜ ê³„ì‚°ì€ êµ­ì†Œì  ê³„ì‚°ì˜ ì „íŒŒë¡œ ì´ë¤„ì§„ë‹¤.
> 
> ì´ì œë¶€í„° ì—­ì „íŒŒë¥¼ ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ í•œ ë‹¨ê³„ì”© ì§šì–´ë³¸ë‹¤.
>
>> **1 ë‹¨ê³„**
>> 
>> '/' ë…¸ë“œ, ì¦‰ y = 1/xì„ ë¯¸ë¶„í•˜ë©´ ë‹¤ìŒ ì‹ì´ ëœë‹¤.
>> 
>> ![ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_1ë‹¨ê³„](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_1ë‹¨ê³„.png)
>> 
>> **2 ë‹¨ê³„**
>> 
>> '+'ë…¸ë“œëŠ” ìƒë¥˜ì˜ ê°’ì„ ì—¬ê³¼ ì—†ì´ í•˜ë¥˜ë¡œ ë‚´ë³´ë‚´ëŠ” ê²Œ ì „ë¶€ë‹¤. ê³„ì‚° ê·¸ë˜í”„ì—ì„  ì•„ë˜ì™€ ê°™ë‹¤.
>> ![ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_2ë‹¨ê³„](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_2ë‹¨ê³„.png)
>> 
>> **3 ë‹¨ê³„**
>> 
>> 'exp'ë…¸ë“œëŠ” y = exp(x)ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©° ê·¸ ë¯¸ë¶„ì€ ì•„ë˜ì™€ ê°™ë‹¤.
>> 
>> ![ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_3ë‹¨ê³„](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_3ë‹¨ê³„.png)
>> 
>> **4 ë‹¨ê³„**
>> 
>> 'x'ë…¸ë“œëŠ” ìˆœì „íŒŒ ë•Œì˜ ê°’ì„ 'ì„œë¡œ ë°”ê¿”'ê³±í•œë‹¤. ì´ ì˜ˆì—ì„œëŠ” -1ì„ ê³±í•œë‹¤.
>> 
>> ![ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_4ë‹¨ê³„](./image/05/ì‹œê·¸ëª¨ì´ë“œ_ê³„ì¸µ_ì—­ì „íŒŒ_4ë‹¨ê³„.png)
>> 
> ê°„ì†Œí™” í•˜ì§€ ì•Šì€ ê³„ì‚° ê·¸ë˜í”„ì™€ ê°„ì†Œí™” í•œ ê³„ì‚° ê·¸ë˜í”„ì˜ ê²°ê³¼ëŠ” ë˜‘ê°™ë‹¤.
> - ê°„ì†Œí™” í•œ ê³„ì‚° ê·¸ë˜í”„ê°€ ì—­ì „íŒŒ ê³¼ì •ì˜ ì¤‘ê°„ ê³„ì‚°ë“¤ì„ ìƒëµí•  ìˆ˜ ìˆì–´ ë” íš¨ìœ¨ì ì¸ ê³„ì‚°ì´ë¼ í•  ìˆ˜ ìˆë‹¤.
> 
> - ë…¸ë“œë¥¼ ê·¸ë£¹í™” í•˜ì—¬ Sigmoidê³„ì¸µì˜ ì„¸ì„¸í•œ ë‚´ìš©ì„ ë…¸ì¶œí•˜ì§€ ì•Šê³  ì…ë ¥ê³¼ ì¶œë ¥ì—ë§Œ ì§‘ì¤‘ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒë„ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë‹¤.
> 
> ![Sigmoid_ê³„ì‚°_ì •ë¦¬](./image/05/Sigmoid_ê³„ì‚°_ì •ë¦¬.png)
> 
> ì´ì²˜ëŸ¼ Sigmoid ê³„ì¸µì˜ ì—­ì „íŒŒëŠ” ìˆœì „íŒŒì˜ ì¶œë ¥(y)ë§Œìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.
> 
> ![Sigmoid_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„](./image/05/Sigmoid_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„.png)
> 
> Sigmoid ê³„ì¸µì„ íŒŒì´ì¬ ì½”ë“œë¥¼ ì´ìš©í•´ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.
> ```Python
> class Sigmoid:
>     def __init__(self):
>         self.out = None
> 
>     def forward(self, x):
>         out = 1 / (1 + np.exp(-x))
>         self.out = out
>         
>         return out
> 
>     def backward(self, dout):
>         dx = dout * (1.0 - self.out) * self.out
> 
>         return dx
> ```
> ìœ„ êµ¬í˜„ì—ì„  ìˆœì „íŒŒì˜ ì¶œë ¥ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ outì— ë³´ê´€í–ˆë‹¤ê°€ ì—­ì „íŒŒ ê³„ì‚°ë•Œ ê·¸ ê°’ì„ ì‚¬ìš©í•œë‹¤.
---
> #### 5.6 Affine/softmax ê³„ì¸µ êµ¬í˜„í•˜ê¸°
> #### 5.6.1 Affine ê³„ì¸µ
> ì‹ ê²½ë§ì˜ ìˆœì „íŒŒ ë•Œ ìˆ˜í–‰í•˜ëŠ” í–‰ë ¬ì˜ ê³±ì€ ê¸°í•˜í•™ì—ì„  **ì–´íŒŒì¸ ë³€í™˜** ì´ë¼ê³  í•œë‹¤. ê·¸ë˜ì„œ ì´ ì±…ì—ì„œ ì–´íŒŒì¸ ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” ì²˜ë¦¬ë¥¼  'Affine ê³„ì¸µ'ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ êµ¬í˜„í•œë‹¤.
> 
> ì‹ ê²½ë§ì˜ ìˆœì „íŒŒì—ì„  ê°€ì¤‘ì¹˜ ì‹ í˜¸ì˜ ì´í•©ì„ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— í–‰ë ¬ì˜ ê³±(numpyì—ì„  np.dot(). [3.3](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_03.md#33-%EB%8B%A4%EC%B0%A8%EC%9B%90-%EB%B0%B0%EC%97%B4%EC%9D%98-%EA%B3%84%EC%82%B0))ì„ ì‚¬ìš©í–ˆë‹¤.
> 
> íŒŒì´ì¬ìœ¼ë¡  ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í–ˆì—ˆë‹¤.
> ``` Python
> X = np.random.rand(2) # ì…ë ¥ 
> W = np.random.rand(2,3) # ê°€ì¤‘ì¹˜
> B = np.random.rand(3) # í¸í–¥ 
> 
> X.shape # (2,) 
> W.shape # (2, 3) 
> B.shape # (3,) 
> 
> Y = np.dot(X, W) + B
> ```
> ì—¬ê¸°ì„  X, W, Bì˜ í˜•ìƒì´ ê°ê° (2,), (2,3), (3,)ì¸ ë‹¤ì°¨ì› ë°°ì—´ì´ë‹¤.
> - ì´ë•Œ ë‰´ëŸ°ì˜ ê°€ì¤‘ì¹˜ í•©ì€ Y = np.dot(X,W) + B ì²˜ëŸ¼ ê³„ì‚°í•œë‹¤.
> 
> ê·¸ë¦¬ê³  Yë¥¼ í™œì„±í™” í•¨ìˆ˜ë¡œ ë³€í™˜í•´ ë‹¤ìŒ ì¸µìœ¼ë¡œ ì „íŒŒí•˜ëŠ” ê²ƒì´ ì‹ ê²½ë§ ìˆœì „íŒŒì˜ íë¦„ì´ë‹¤.
> 
> í–‰ë ¬ì˜ ê³± ê³„ì‚°ì€ ëŒ€ì‘í•˜ëŠ” ì°¨ì›ì˜ ì›ì†Œ ìˆ˜ë¥¼ ì¼ì¹˜ì‹œí‚¤ëŠ”ê²Œ í•µì‹¬ì´ë‹¤.
> - Xì™€ Wì˜ ê³±ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ëŒ€ì‘í•˜ëŠ” ì°¨ì›ì˜ ì›ì†Œ ìˆ˜ë¥¼ ì¼ì¹˜ì‹œì¼œì•¼ í•œë‹¤.
> 
> ![5_23](./image/05/5_23.png)
> 
> ì•ì—ì„œ ìˆ˜í–‰í•œ ê³„ì‚°(í–‰ë ¬ì˜ ê³±ê³¼ í¸í–¥ì˜ í•©)ì„ ê³„ì‚° ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³¸ë‹¤.
> - ê³±ì„ ê³„ì‚°í•˜ëŠ” ë…¸ë“œë¥¼ 'dot'ë¼ê³  í•˜ë©´ np.dot(X, W) + B ê³„ì‚°ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ê·¸ë ¤ì§„ë‹¤. 
> 
> - ë˜í•œ, ê° ë³€ìˆ˜ì˜ ì´ë¦„ ìœ„ì— ê·¸ ë³€ìˆ˜ì˜ í˜•ìƒì„ í‘œì‹œí•œë‹¤.(ì•„ë˜ ê·¸ë¦¼ì—ì„œ Xì˜ í˜•ìƒì€(2,), ğ‘‹âˆ™ğ‘Šì˜ í˜•ìƒì€ (3,)ì„ì„ í‘œê¸°í•¨
> 
> ![Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„_1](./image/05/Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„_1.png)
> 
> ë¹„êµì  ë‹¨ìˆœí•œ ê³„ì‚° ê·¸ë˜í”„ë‹¤. ë‹¨, X, W, Bê°€ í–‰ë ¬(ë‹¤ì°¨ì› ë°°ì—´)ì´ë¼ëŠ” ì ì— ì£¼ì˜í•´ì•¼í•œë‹¤.
> 
> ì§€ê¸ˆê¹Œì§€ ê³„ì‚° ê·¸ë˜í”„ëŠ” ë…¸ë“œ ì‚¬ì´ì— '[ìŠ¤ì¹¼ë¼ê°’](https://wikidocs.net/22383)' ì´ íë¥¸ê²ƒì— ë°˜í•´ ìœ„ ì˜ˆì—ì„œëŠ” 'í–‰ë ¬'ì´ íë¥´ê³  ìˆë‹¤.
> 
> ì´ì œ ìœ„ ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒì— ëŒ€í•´ ìƒê°í•´ë³¸ë‹¤.
> 
> í–‰ë ¬ì„ ì‚¬ìš©í•œ ì—­ì „íŒŒë„ í–‰ë ¬ì˜ ì›ì†Œë§ˆë‹¤ ì „ê°œí•´ë³´ë©´ ìŠ¤ì¹¼ë¼ê°’ì„ ì‚¬ìš©í•œ ê³„ì‚° ê·¸ë˜í”„ì™€ ê°™ì€ ìˆœì„œë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤.
> - ì‹¤ì œë¡œ ì „ê°œí•´ë³´ë©´ ì•„ë˜ì˜ ì‹ì´ ë„ì¶œëœë‹¤.
> 
> #### 1
> ![ì‹5_13](./image/05/ì‹5_13.png)
> 
> ìœ„ ì‹ì—ì„œ W^Tì˜ TëŠ” ì „ì¹˜í–‰ë ¬ì„ ëœ»í•œë‹¤. 
> - ì „ì¹˜í–‰ë ¬ì€ Wì˜ (i,j)ìœ„ì¹˜ì˜ ì›ì†Œë¥¼ (j, i)ìœ„ì¹˜ë¡œ ë°”ê¾¼ê²ƒì„ ë§í•œë‹¤. ìˆ˜ì‹ìœ¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤.
> 
> ![ì‹5_14](./image/05/ì‹5_14.png)
> 
> Wì˜ í˜•ìƒì´ (2,3)ì´ì—ˆë‹¤ë©´ ì „ì¹˜í–‰ë ¬ W^Tì˜ í˜•ìƒì€(3,2)ê°€ ëœë‹¤.
> - ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ê³„ì‚°ê·¸ë˜í”„ì˜ ì—­ì „íŒŒë¥¼ êµ¬í•˜ë©´ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
> 
> ![Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„_2](./image/05/Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„_2.png)
> 
> ìœ„ ê³„ì‚° ê·¸ë˜í”„ì—ì„œ ê° ë³€ìˆ˜ì˜ í˜•ìƒì— ì£¼ì˜í•´ì„œ ì‚´í´ë³¸ë‹¤.
> - íŠ¹íˆ Xì™€ ğœ•L/ğœ•Xì€ ê°™ì€ í˜•ìƒì´ê³  Wì™€ ğœ•L/ğœ•Wë„ ê°™ì€ í˜•ìƒì´ë‹¤. ì•„ë˜ ì‹ì„ í†µí•´ í™•ì¸í•œë‹¤.
> 
> ![ì‹5_15](./image/05/ì‹5_15.png)
> 
> í–‰ë ¬ì˜ ê³±ì—ì„  ëŒ€ì‘í•˜ëŠ” ì°¨ì›ì˜ ì›ì†Œ ìˆ˜ë¥¼ ì¼ì¹˜ì‹œì¼œì•¼ í•˜ëŠ”ë° [ì•ì—ì„œ ë³¸ ì‹](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#1)ì„ ë™ì›í•´ì•¼ í•  ìˆ˜ë„ ìˆê¸° ë•Œë¬¸ì´ë‹¤.
> 
> ì˜ˆë¥¼ ë“¤ì–´ ğœ•L/ğœ•Wì˜ í˜•ìƒì´ (3,)ì´ê³  Wì˜ í˜•ìƒì´ (2,3) ì¼ë•Œ ğœ•L/ğœ•Xì˜ í˜•ìƒì´ (2,)ê°€ ë˜ëŠ” ğœ•L/ğœ•Yê³¼ Wì„ ê³±ì„ ìƒê°í•´ ë³´ë©´ [ì•ì—ì„œ ë³¸ ì‹](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_05.md#1) ì´ ìœ ë„ ë  ê²ƒì´ë¼ í•œë‹¤.
> - ì•„ë˜ì™€ ê°™ì´ ê·¸ë ¤ì§ˆ ê²ƒì´ë‹¤.
> 
> ![5_26](./image/05/5_26.png)
> 
> #### 5.6.2 ë°°ì¹˜ìš© Affine ê³„ì¸µ
> ì´ë²ˆì—” ë°ì´í„° Nê°œë¥¼ ë¬¶ì–´ ìˆœì „íŒŒ í•˜ëŠ” ê²½ìš°, ì¦‰ ë°°ì¹˜ìš© Affineê³„ì¸µì„ ìƒê°í•´ ë³¸ë‹¤(ë¬¶ì€ ë°ì´í„° = ë°°ì¹˜)
> 
> ![ë°°ì¹˜ìš©_Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„](./image/05/ë°°ì¹˜ìš©_Affine_ê³„ì¸µì˜_ê³„ì‚°_ê·¸ë˜í”„.png)
>
> ë°°ì¹˜ìš© Affine ê³„ì¸µì˜ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ë‹¤. 
>
> ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ì€ ì…ë ¥ì¸ Xì˜ í˜•ìƒì´ (N,2)ê°€ ëœ ê²ƒë¿ì´ë‹¤. ë‹¤ë¥¸ ê²ƒì€ ì§€ê¸ˆê¹Œì§€ì™€ ê°™ì´ ê³„ì‚° ê·¸ë˜í”„ì˜ ìˆœì„œë¥¼ ë”°ë¼ í–‰ë ¬ ê³„ì‚°ì„ í•˜ê²Œ ëœë‹¤.
> 
> ë˜í•œ ì—­ì „íŒŒ ë•ŒëŠ” í–‰ë ¬ì˜ í˜•ìƒì— ì£¼ì˜í•˜ë©´ ğœ•L/ğœ•Xê³¼ ğœ•L/ğœ•Wì€ ì´ì „ê³¼ ê°™ì´ ë„ì¶œí•  ìˆ˜ ìˆë‹¤.
> 
> í¸í–¥ì„ ë”í•  ë•Œì—ë„ ì£¼ì˜í•´ì•¼í•œë‹¤.
> - ìˆœì „íŒŒ ë•Œì˜ í¸í–¥ ë§ì…ˆì€ **X âˆ™ W**ì— ëŒ€í•œ í¸í–¥ì´ ê° ë°ì´í„°ì— ë”í•´ì§„ë‹¤.
> 
>> N=2(ë°ì´í„°ê°€ 2ê°œ)ë¡œ í•œ ê²½ìœ¼ í¸í–¥ì€ ê·¸ ë‘ ë°ì´í„° ê°ê°ì—(ê°ê°ì˜ ê³„ì‚° ê²°ê³¼ì—)ë”í•´ì§„ë‹¤.
>> ```Python
>> X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])
>> B = np.array([1, 2, 3])
>> 
>> print(X_dot_W)
>> # array([[ 0, 0, 0], [ 10, 10, 10]])
>> print(X_dot_W + B)
>> # array([[ 1, 2, 3], [ 11, 12, 13]])
>> ```
>
> ìˆœì „íŒŒì˜ í¸í–¥ì˜ ë§ì…ˆì€ ê°ê°ì˜ ë°ì´í„°(1ë²ˆì§¸, 2ë²ˆì§¸, ...)ì— ë”í•´ì§„ë‹¤. ê·¸ë˜ì„œ ì—­ì „íŒŒ ë•ŒëŠ” ê° ë°ì´í„°ì˜ ì—­ì „íŒŒ ê°’ì´ í¸í–¥ì˜ ì›ì†Œì— ëª¨ì—¬ì•¼ í•œë‹¤. ì½”ë“œë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.
> 
> ```Python
> dY = np.array([[1, 2, 3], [4, 5, 6]])
> print(dY)
> # array([[1, 2, 3], [4, 5, 6]]) 
> 
> dB = np.sum(dY, axis=0)
> print(dB)
> # array([5, 7, 9])
> ```
> ìœ„ ì˜ˆì—ì„  ë°ì´í„°ê°€ 2ê°œ(N=2)ë¼ê³  ê°€ì •í•œë‹¤. í¸í–¥ì˜ ì—­ì „íŒŒëŠ” ê·¸ ë‘ ë°ì´í„°ì— ëŒ€í•œ ë¯¸ë¶„ì„ ë°ì´í„°ë§ˆë‹¤ ë”í•˜ì—¬ êµ¬í•œë‹¤.
> - np.sum()ì—ì„œ 0ë²ˆì§¸ ì¶•(ë°ì´í„°ë¥¼ ë‹¨ìœ„ë¡œ í•œ ì¶•)ì— ëŒ€í•´ (axis=0)ì˜ ì´í•©ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.
> 
> ì´ìƒì˜ Affineêµ¬í˜„ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
> ```Python
> class Affine:
>     def __init__(self, W, b):
>         self.W = W
>         self.b = b
>         self.x = None
>         self.dW = None
>         self.db = None
> 
>     def forward(self, x):
>         self.x = x
>         out = np.dot(x, self.W) + self.b
>         
>         return out
>     
>     def backward(self, dout):
>         dx = np.dot(dout, self.W.T)
>         self.dW = np.dot(self.x.T, dout)
>         self.db = np.sum(dout, axis=0)
>         
>         return dx
> ```
> 
> #### 5.6.3 Softmax-with-Loss ê³„ì¸µ
> ì¶œë ¥ì¸µì—ì„œ ì‚¬ìš©í•˜ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì— ê´€í•´ ì„¤ëª…í•œë‹¤.
> 
> ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ì…ë ¥ ê°’ì„ ì •ê·œí™”í•˜ì—¬ ì¶œë ¥í•œë‹¤.
> - ì†ê¸€ì”¨ ìˆ«ì ì¸ì‹ì—ì„œ softmax ê³„ì¸µì˜ ì¶œë ¥ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤.
> 
> ![fig_5_28](./image/05/fig_5_28.png)
> 
> - ì¶œì²˜ [ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹, íŒŒì´ì¬ìœ¼ë¡œ ìµíˆëŠ” ë”¥ëŸ¬ë‹ ì´ë¡ ê³¼ êµ¬í˜„](https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198)
> 
> ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ Softmax ê³„ì¸µì€ ì…ë ¥ ê°’ì„ ì •ê·œí™”(ì¶œë ¥ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ë³€í˜•)í•˜ì—¬ ì¶œë ¥í•œë‹¤.
> 
> ë˜í•œ ì†ê¸€ì‹œ ìˆ«ìëŠ” ê°€ì§“ìˆ˜ê°€ 10ê°œ(10í´ë˜ìŠ¤ ë¶„ë¥˜)ì´ë¯€ë¡œ Softmax ê³„ì¸µì˜ ì…ë ¥ì€ 10ê°œê°€ ëœë‹¤.
> 
>> ì‹ ê²½ë§ì—ì„œ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…ì€ **í•™ìŠµ**ê³¼ **ì¶”ë¡ ** ë‘ ê°€ì§€ë‹¤. ì¶”ë¡ í•  ë•ŒëŠ” ì¼ë°˜ì ìœ¼ë¡œ Softmaxê³„ì¸µì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
>> 
>> ìœ„ ê·¸ë¦¼ì˜ ì‹ ê²½ë§ì€ ì¶”ë¡ í•  ë•Œ ë§ˆì§€ë§‰ Affineê³„ì¸µì˜ ì¶œë ¥ì„ ì¸ì‹ ê²°ê³¼ë¡œ ì´ìš©í•œë‹¤. ë˜í•œ ì‹ ê²½ë§ì—ì„œ ì •ê·œí™”í•˜ì§€ ì•ŠëŠ” ì¶œë ¥ ê²°ê³¼(ìœ„ ê·¸ë¦¼ì—ì„œëŠ” Softmax ì•ì˜ Affine ê³„ì¸µì˜ ì¶œë ¥)ë¥¼ **ì ìˆ˜**ë¼ í•œë‹¤.
>> 
>> ì¦‰ ì‹ ê²½ë§ ì¶”ë¡ ì—ì„œ ë‹µì„ í•˜ë‚˜ë§Œ ë‚´ëŠ” ê²½ìš°ì—ëŠ” ê°€ì¥ ë†’ì€ ì ìˆ˜ë§Œ ì•Œë©´ ë˜ëŠ” ê²ƒì´ë¯€ë¡œ Softmaxê³„ì¸µì€ í•„ìš”ê°€ ì—†ë‹¤ëŠ” ê²ƒì´ë‹¤. ë°˜ë©´ ì‹ ê²½ë§ì„ í•™ìŠµí•  ë• Softmaxê³„ì¸µì´ í•„ìš”í•˜ë‹¤. 
>
> ì´ì œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ê³„ì¸µì„ êµ¬í˜„í•œë‹¤. ì†ì‹¤ í•¨ìˆ˜ì¸ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ë„ í¬í•¨í•˜ì—¬ '**Softmax-with-Loss ê³„ì¸µ**'ì´ë€ ì´ë¦„ìœ¼ë¡œ êµ¬í˜„í•œë‹¤.
> - ë¨¼ì € ì•„ë˜ì˜ Softmax-with-Loss ê³„ì¸µì˜ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì‚´í´ë³¸ë‹¤.
> 
> <img src="./image/05/fig_5_29.png" width="800" height="300">
> 
> - ì¶œì²˜ [ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹, íŒŒì´ì¬ìœ¼ë¡œ ìµíˆëŠ” ë”¥ëŸ¬ë‹ ì´ë¡ ê³¼ êµ¬í˜„](https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198)
> 
> Softmax-with-Loss ê³„ì¸µì€ ë‹¤ì†Œ ë³µì¡í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ìœ„ ê³„ì‚° ê·¸ë˜í”„ëŠ” ì•„ë˜ì™€ ê°™ì´ ê°„ì†Œí™” í•  ìˆ˜ ìˆë‹¤.
> 
> ![ê°„ì†Œí™”í•œ_Softmax_ê³„ì¸µ_ê³„ì‚°_ê·¸ë˜í”„](./image/05/ê°„ì†Œí™”í•œ_Softmax_ê³„ì¸µ_ê³„ì‚°_ê·¸ë˜í”„.png)
> 
> ìœ„ ê·¸ë¦¼ì˜ ê³„ì‚°ê·¸ë˜í”„ì—ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” 'Softmax'ê³„ì¸µìœ¼ë¡œ, êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ëŠ” 'Cross Entropy Error'ê³„ì¸µìœ¼ë¡œ í‘œê¸° í–ˆë‹¤.
> 
> ì—¬ê¸°ì„  3í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ê°€ì •í•˜ê³  ì´ì „ ê³„ì¸µì—ì„œ 3ê°œì˜ ì…ë ¥(ì ìˆ˜)ì„ ë°›ëŠ”ë‹¤. ê·¸ë¦¼ê³¼ ê°™ì´ Softmaxê³„ì¸µì€ ì…ë ¥(a_1, a_2, a_3)ë¥¼ ì •ê·œí™” í•˜ì—¬ (y_1, y_2, y_3)ë¥¼ ì¶œë ¥í•œë‹¤.
> 
> Cross Entropy Error ê³„ì¸µì€ Softmaxì˜ ì¶œë ¥(y_1, y_2, y_3)ì™€ ì •ë‹µ ë ˆì´ë¸”(t_1, t_2, t_3)ë¥¼ ë°›ê³  ì´ ë°ì´í„°ë“¤ë¡œ ë¶€í„° ì†ì‹¤ Lì„ ì¶œë ¥í•œë‹¤.
> 
> ìœ„ ê·¸ë¦¼ì—ì„œ ê°€ì¥ ì£¼ëª©í•  ì ì€ ì—­ì „íŒŒì˜ ê²°ê³¼í•˜ê³  í•œë‹¤. 
> 
> Softmax ê³„ì¸µì˜ ì—­ì „íŒŒëŠ” (y_1-t_1, y_2-t_2, y_3-t_3)ë¼ëŠ” ë§ë”í•œ ê²°ê³¼ë¥¼ ë‚´ë†“ëŠ”ë‹¤. (y_1~3)ì€ Softmaxê³„ì¸µì˜ ì¶œë ¥ì´ê³  (t_1~3)ì€ ì •ë‹µ ë ˆì´ë¸”ì´ë¯€ë¡œ (y_1-t_1, y_2-t_2, y_3-t_3)ëŠ” Softmaxê³„ì¸µì˜ ì¶œë ¥ê³¼ ì •ë‹µ ë ˆì´ë¸”ì˜ ì°¨ë¶„ì¸ ê²ƒì´ë‹¤.
> 
> ì‹ ê²½ë§ì˜ ì—­ì „íŒŒì—ì„  ì´ ì°¨ì´ì¸ ì˜¤ì°¨ê°€ ì• ê³„ì¸µì— ì „í•´ì§€ëŠ” ê²ƒì´ë‹¤. 
> - ì´ ê²ƒì€ ì‹ ê²½ë§ í•™ìŠµì˜ ì¤‘ìš”í•œ ì„±ì§ˆì´ë‹¤.
> 
> ê·¸ëŸ°ë° ì‹ ê²½ë§ í•™ìŠµì˜ ëª©ì ì€ ì¶œë ¥(Softmaxì˜ ì¶œë ¥)ì´ ì •ë‹µ ë ˆì´ë¸”ê³¼ ê°€ê¹Œì›Œì§€ë„ë¡ ë§¤ê°œë³€ìˆ˜ì˜ ê°’ì„ ì¡°ì •í•˜ëŠ” ê²ƒì´ì˜€ë‹¤.
> - ê·¸ë˜ì„œ ì‹ ê²½ë§ì˜ ì¶œë ¥ê³¼ ì •ë‹µ ë ˆì´ë¸”ì˜ ì˜¤ì°¨ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì• ê³„ì¸µì— ì „ë‹¬í•´ì•¼ í•œë‹¤.
> 
> ì•ì˜ (y_1-t_1, y_2-t_2, y_3-t_3)ë¼ëŠ” ê²°ê³¼ëŠ” ë°”ë¡œ Softmaxê³„ì¸µì˜ ì¶œë ¥ê³¼ ì •ë‹µ ë ˆì´ë¸”ì˜ ì°¨ì´ë¡œ, ì‹ ê²½ë§ì˜ í˜„ì¬ ì¶œë ¥ê³¼ ì •ë‹µ ë ˆì´ë¸”ì˜ ì˜¤ì°¨ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ë“œëŸ¬ë‚´ëŠ” ê²ƒì´ë‹¤.
> 
>> 'ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜'ì˜ ì†ì‹¤ í•¨ì†Œë¡œ 'êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨'ë¥¼ ì‚¬ìš©í•˜ë‹ˆ ì—­ì „íŒŒê°€ (y_1-t_1, y_2-t_2, y_3-t_3) ë¡œ ë§ë”íˆ ë–¨ì–´ì§„ë‹¤. ì´ëŸ° ë§ë”í•¨ì€ ìš°ì—°ì´ ì•„ë‹ˆë¼ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨ë¼ëŠ” í•¨ìˆ˜ê°€ ê·¸ë ‡ê²Œ ì„¤ê³„ë˜ì–´ìˆê¸° ë•Œë¬¸ì´ë‹¤.
>> 
>> ë˜ íšŒê·€ì˜ ì¶œë ¥ì¸µì—ì„œ ì‚¬ìš©í•˜ëŠ” 'í•­ë“± í•¨ìˆ˜'ì˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ 'ì˜¤ì°¨ì œê³±í•©'ì„ ì´ìš©([3.5 ì¶œë ¥ì¸µ ì„¤ê³„í•˜ê¸°](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_03.md#35-%EC%B6%9C%EB%A0%A5%EC%B8%B5-%EC%84%A4%EA%B3%84%ED%95%98%EA%B8%B0))í•˜ëŠ” ì´ìœ ë„ ì´ì™€ ê°™ë‹¤.
>> 
>> ì¦‰ 'í•­ë“± í•¨ìˆ˜'ì˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ 'ì˜¤ì°¨ì œê³±í•©'ì„ ì‚¬ìš©í•˜ë©´ ì—­ì „íŒŒì˜ ê²°ê³¼ê°€ (y_1-t_1, y_2-t_2, y_3-t_3)ë¡œ ë§ë”íˆ ë–¨ì–´ì§„ë‹¤.
>> 
>
> ```Python
> class SoftmaxWithLoss:
>     def __init__(self):
>         self.loss = None # ì†ì‹¤
>         self.y = None # softmaxì˜ ì¶œë ¥
>         self.t = None # ì •ë‹µ ë ˆì´ë¸”(ì›-í•« ë²¡í„°)
>         
>     def forward(self, x, t):
>         self.t = t
>         self.y = softmax(x)
>         self.loss = cross_entropy_error(self.y, self.t)
>         return self.loss
>         
>     def backward(self, dout=1):
>         batch_size = self.t.shape[0]
>         dx = (self.y - self.t) / batch_size
>         return dx
> ```
> ìœ„ ì½”ë“œëŠ” íŒŒì´ì„  ì½”ë“œë¥¼ ì´ìš©í•´ Softmax-with-Loss ê³„ì¸µì„ êµ¬í˜„í•œ ê²ƒì´ë‹¤.
> 
> [3.5.2](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_03.md#352-%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4-%ED%95%A8%EC%88%98-%EA%B5%AC%ED%98%84-%EC%8B%9C-%EC%A3%BC%EC%9D%98%EC%A0%90)ì˜ ë‚´ìš©ê³¼ [4.2.4](https://github.com/minchan5224/TIL/blob/main/Python/Deep_Learning/Deep_01_04.md#424-%EB%B0%B0%EC%B9%98%EC%9A%A9%EA%B5%90%EC%B0%A8-%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC-%EC%98%A4%EC%B0%A8-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0)ì—ì„œ êµ¬í˜„í•œ ë‚´ìš©ì„ í† ëŒ€ë¡œ êµ¬í˜„í•˜ì˜€ë‹¤.
> - ì—­ì „íŒŒ ë•ŒëŠ” ì „íŒŒí•˜ëŠ” ê°’ì„ ë°°ì¹˜ì˜ ìˆ˜(batch_size)ë¡œ ë‚˜ëˆ„ì–´ ë°ì´í„° 1ê°œë‹¹ ì˜¤ì°¨ë¥¼ ì• ê³„ì¸µìœ¼ë¡œ ì „íŒŒí•˜ëŠ” ì ì— ì£¼ì˜í•´ì•¼í•œë‹¤.
> 
> #### 5.7 ì˜¤ì°¨ì—­ì „íŒŒë²• êµ¬í˜„í•˜ê¸°
> ì´ì œ ì§€ê¸ˆê¹Œì§€ êµ¬í˜„í•œ ê³„ì¸µì„ ì¡°í•©í•´ ì‹ ê²½ë§ì„ êµ¬ì¶•í•œë‹¤.
> 
> #### 5.7.1 ì‹ ê²½ë§ í•™ìŠµì˜ ì „ì²´ ê·¸ë¦¼
> 
> 4.5ì—ì„œ ë³¸ ê²ƒê³¼ ê°™ì€ ìˆœì„œë¡œ ì‹ ê²½ë§ í•™ìŠµì„ ì§„í–‰í•œë‹¤.
> 
> **ì „ì œ**
>> ì‹ ê²½ë§ì—ëŠ” ì ì‘ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì´ ìˆê³ , ì´ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì„ í›ˆë ¨ ë°ì´í„°ì— ì ì‘í•˜ë„ë¡ ì¡°ì •í•˜ëŠ” ê³¼ì •ì„ 'í•™ìŠµ'ì´ë¼ í•œë‹¤. 
>>
>> ì‹ ê²½ë§ í•™ìŠµì€ ì•„ë˜ì™€ ê°™ì´ 4ë‹¨ê³„ë¡œ ìˆ˜í–‰í•œë‹¤.
>>
>> **1ë‹¨ê³„-ë¯¸ë‹ˆë°°ì¹˜**
>>> í›ˆë ¨ ë°ì´í„° ì¤‘ ì¼ë¶€ë¥¼ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì˜¨ë‹¤. ì´ë ‡ê²Œ ì„ ë³„í•œ ë°ì´í„°ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ë¼ í•˜ë©° ë¯¸ë‹ˆë°°ì¹˜ì˜ ì†ì‹¤ í•¨ìˆ˜ ê°’ì„ ì¤„ì´ëŠ” ê²ƒì´ ëª©í‘œë‹¤.
>>
>> **2ë‹¨ê³„-ê¸°ìš¸ê¸° ì‚°ì¶œ**
>>> ë¯¸ë‹ˆë°°ì¹˜ì˜ ì†ì‹¤ í•¨ìˆ˜ ê°’ì„ ì¤„ì´ê¸° ìœ„í•´ ê° ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œê°€. ê¸°ìš¸ê¸°ëŠ” ì†ì‹¤ í•¨ìˆ˜ì˜ ê°’ì„ ê°€ì¥ ì‘ê²Œ í•˜ëŠ” ë°©í–¥ì„ ì œì‹œí•œë‹¤.
>>
>> **3ë‹¨ê³„-ë§¤ê°œë³€ìˆ˜ ê°±ì‹ **
>>> ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê¸°ìš¸ê¸° ë°©í–¥ìœ¼ë¡œ ì•„ì£¼ ì¡°ê¸ˆ ê°±ì‹ í•œë‹¤.
>>
>> **4ë‹¨ê³„-ë°˜ë³µ**
>>> 1~3ë‹¨ê³„ë¥¼ ë°˜ë³µí•œë‹¤.
>>
> ì§€ê¸ˆê¹Œì§€ í•™ìŠµí•œ ì˜¤ì°¨ì—­ì „íŒŒë²•ì´ ë“±ì¥í•˜ëŠ” ë‹¨ê³„ëŠ” ë‘ ë²ˆì§¸ì¸ 'ê¸°ìš¸ê¸° ì‚°ì¶œ'ë‹¨ê³„ë‹¤.
> - ì•ì¥(4ì¥)ì—ì„  ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ ìˆ˜ì¹˜ ë¯¸ë¶„ì„ ì‚¬ìš©í–ˆì§€ë§Œ ê³„ì‚°ì´ ì˜¤ë˜ê±¸ë¦°ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. 
> 
> - ì˜¤ì°¨ì—­ì „íŒŒë²•ì„ ì´ìš©í•´ ìˆ˜ì¹˜ ë¯¸ë¶„ê³¼ ë‹¬ë¦¬ ê¸°ìš¸ê¸°ë¥¼ íš¨ìœ¨ì ì´ê³  ë¹ ë¥´ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.
> 
> #### 5.7.2 ì˜¤ì°¨ì—­ì „íŒŒë²•ì„ ì ìš©í•œ ì‹ ê²½ë§ êµ¬í˜„í•˜ê¸°
> 2ì¸µ ì‹ ê²½ë§ì„ TwoLayerNet í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•œë‹¤.
> 
> ì•„ë˜ ê·¸ë¦¼ì€ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì™€ ë©”ì„œë“œë¥¼ ì •ë¦¬í•œ í‘œë‹¤.
> 
> ![TLN_ë³€ìˆ˜_ë©”ì„œë“œ](./image/05/TLN_ë³€ìˆ˜_ë©”ì„œë“œ.png)
> 
> 4ì¥ì—ì„œ í•™ìŠµí•œ ê²ƒê³¼ ê³µí†µë˜ëŠ” ë¶€ë¶„ì´ ë§ë‹¤.
> - í¬ê²Œ ë‹¤ë¥¸ ë¶€ë¶„ì€ ê³„ì¸µì„ ì‚¬ìš©í•˜ëŠ” ì ì´ë‹¤. 
> 
> ê³„ì¸µì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì¸ì‹ ê²°ê³¼ë¥¼ ì–»ëŠ” ì²˜ë¦¬(predict())ì™€ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ëŠ” ì²˜ë¦¬(gradient()) ê³„ì¸µì˜ ì „íŒŒë§Œìœ¼ë¡œ ë™ì‘ì´ ì´ë£¨ì–´ì§€ëŠ” ê²ƒì´ë‹¤.
> 
> ```Python
> import sys, os
> sys.path.append(os.pardir)  # ë¶€ëª¨ ë””ë ‰í„°ë¦¬ì˜ íŒŒì¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ì„¤ì •
> import numpy as np
> from common.layers import *
> from common.gradient import numerical_gradient
> from collections import OrderedDict
> 
> 
> class TwoLayerNet:
> 
>     def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):
>         # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
>         self.params = {}
>         self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
>         self.params['b1'] = np.zeros(hidden_size)
>         self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) 
>         self.params['b2'] = np.zeros(output_size)
> 
>         # ê³„ì¸µ ìƒì„±
>         self.layers = OrderedDict() # ìˆœì„œê°€ ìˆëŠ” ë”•ì…”ë„ˆë¦¬.(ì¶”ê°€í•œ ìˆœì„œ ê¸°ì–µ)
>         self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1']) # 1ë²ˆ Affine
>         self.layers['Relu1'] = Relu() # 1ë²ˆ Relu
>         self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2']) # 2ë²ˆ Affine
> 
>         self.lastLayer = SoftmaxWithLoss()
>         
>     def predict(self, x):
>         for layer in self.layers.values():
>             x = layer.forward(x) # ìˆœì „íŒŒ ì‹¤í–‰
>         
>         return x
>         
>     # x : ì…ë ¥ ë°ì´í„°, t : ì •ë‹µ ë ˆì´ë¸”
>     def loss(self, x, t):
>         y = self.predict(x) 
>         return self.lastLayer.forward(y, t) # ì¼ë°˜ ê³„ì¸µ ìˆœì „íŒŒ ëë‚˜ê³  ë§ˆì§€ë§‰ ì¸µ ìˆœì „íŒŒ ì‹¤í–‰(ì˜¤ë¥¸ìª½ â†’ ì™¼ìª½)
>     
>     def accuracy(self, x, t):
>         y = self.predict(x)
>         y = np.argmax(y, axis=1)
>         if t.ndim != 1 : t = np.argmax(t, axis=1)
>         
>         accuracy = np.sum(y == t) / float(x.shape[0])
>         return accuracy
>         
>     # x : ì…ë ¥ ë°ì´í„°, t : ì •ë‹µ ë ˆì´ë¸”
>     def numerical_gradient(self, x, t):
>         loss_W = lambda W: self.loss(x, t)
>         
>         grads = {}
>         grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
>         grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
>         grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
>         grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
>         
>         return grads
>         
>     def gradient(self, x, t):
>         # forward
>         self.loss(x, t)
> 
>         # backward
>         dout = 1
>         dout = self.lastLayer.backward(dout) # ë§ˆì§€ë§‰ ì¸µë¶€í„° ì—­ì „íŒŒ ì‹œì‘ (ì™¼ìª½ â†’ ì˜¤ë¥¸ìª½)
>         
>         layers = list(self.layers.values())
>         layers.reverse() # ìˆœì „íŒŒì™€ ë°˜ëŒ€ ìˆœì„œë¡œ ì—­ì „íŒŒ ì§„í–‰
>         for layer in layers:
>             dout = layer.backward(dout) # ìˆœì „íŒŒì™€ ë°˜ëŒ€ ìˆœì„œë¡œ ì—­ì „íŒŒ ì§„í–‰
> 
>         # ê²°ê³¼ ì €ì¥
>         grads = {}
>         grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db
>         grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db
> 
>         return grads
> ```
> ì‹ ê²½ë§ì˜ ê³„ì¸µì„ OrderedDict()ì— ì €ì¥í•˜ëŠ” ì ì´ ì¤‘ìš”í•˜ë‹¤.
> 
> ìˆœì„œê°€ ìˆëŠ” ë”•ì…”ë„ˆë¦¬ì´ë©° ê°’ì„ ì €ì¥í•œ ìˆœì„œë¥¼ ê¸°ì–µí•œë‹¤. ë”°ë¼ì„œ ìˆœì „íŒŒ ë•Œì—” forward()ë¥¼ í˜¸ì¶œí•˜ë©´ ë˜ëŠ” ê²ƒì´ê³  ì—­ì „íŒŒ ë•Œì—ëŠ” ë°˜ëŒ€ìˆœì„œ ëŒ€ë¡œ í˜¸ì¶œí•˜ë©´ ëœë‹¤.
> 
> Affine ê³„ì¸µê³¼ ReLU ê³„ì¸µì´ ê°ìì˜ ë‚´ë¶€ì—ì„œ ìˆœì „íŒŒì™€ ì—­ì „íŒŒë¥¼ ì œëŒ€ë¡œ ì²˜ë¦¬í•˜ê³  ìˆìœ¼ë‹ˆ ì—¬ê¸°ì„  ê³„ì¸µì„ ì˜¬ë°”ë¥¸ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•˜ê³  ìˆœì„œëŒ€ë¡œ(ì—­ìˆœìœ¼ë¡œ) í˜¸ì¶œí•˜ë©´ ëœë‹¤.
> 
> ì´ì™€ê°™ì´ ì‹ ê²½ë§ì˜ êµ¬ì„± ìš”ì†Œë¥¼ 'ê³„ì¸µ'ìœ¼ë¡œ êµ¬í˜„í•´ ë” ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.
> 
> 'ê³„ì¸µ'ìœ¼ë¡œ ëª¨ë“ˆí™” í•˜ì—¬ êµ¬í˜„í•œë‹¤ë©´ ë” ê¹Šì€ ì‹ ê²½ë§ì„ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ í•„ìš”í•œ ë§Œí¼ ê³„ì¸µì„ ì¶”ê°€í•˜ê¸°ë§Œ í•˜ë©´ ëœë‹¤.
> 
> #### 5.7.3 ì˜¤ì°¨ì—­ì „íŒŒë²•ìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸° ê²€ì¦í•˜ê¸°
> ìˆ˜ì¹˜ ë¯¸ë¶„ì˜ ì´ì ì€ êµ¬í˜„í•˜ê¸° ì‰½ë‹¤ëŠ” ì ì´ë‹¤ ê·¸ë§Œí¼ êµ¬í˜„ì— ë²„ê·¸ê°€ ìˆ¨ì–´ ìˆê¸° ì–´ë µë‹¤ í•˜ì§€ë§Œ ì˜¤ì°¨ì—­ì „íŒŒë²•ì€ ë¹ ë¥´ì§€ë§Œ êµ¬í˜„ì´ ì–´ë µë‹¤ ê·¸ë§Œí¼ ì‹¤ìˆ˜ê°€ ë°œìƒ í•˜ê³¤ í•œë‹¤.
> 
> ì´ëŸ¬í•œ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ìˆ˜ì¹˜ ë¯¸ë¶„ì˜ ê²°ê³¼ì™€ ì˜¤ì°¨ì—­ì „íŒŒë²•ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ ì˜¤ì°¨ì—­ì „íŒŒë²•ì´ ì œëŒ€ë¡œ êµ¬í˜„ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•œë‹¤ê³  í•œë‹¤.
> 
> ì´ì™€ê°™ì´ ë‘ ë°©ì‹ìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸°ê°€ ì¼ì¹˜í•¨(ê±°ì˜ ê°™ìŒ)ì„ í™•ì¸í•˜ëŠ” ì‘ì—…ì„ **ê¸°ìš¸ê¸° í™•ì¸**ì´ë¼ê³  í•˜ë©° ì•„ë˜ì™€ ê°™ì´ êµ¬í˜„í•œë‹¤.
> ```Python
> import sys, os
> sys.path.append(os.pardir)  # ë¶€ëª¨ ë””ë ‰í„°ë¦¬ì˜ íŒŒì¼ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ ì„¤ì •
> import numpy as np
> from dataset.mnist import load_mnist
> from two_layer_net import TwoLayerNet
> 
> # ë°ì´í„° ì½ê¸°
> (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)
> 
> network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)
> 
> x_batch = x_train[:3]
> t_batch = t_train[:3]
> 
> grad_numerical = network.numerical_gradient(x_batch, t_batch)
> grad_backprop = network.gradient(x_batch, t_batch)
> 
> # ê° ê°€ì¤‘ì¹˜ì˜ ì°¨ì´ì˜ ì ˆëŒ“ê°’ì„ êµ¬í•œ í›„, ê·¸ ì ˆëŒ“ê°’ë“¤ì˜ í‰ê· ì„ ë‚¸ë‹¤.
> for key in grad_numerical.keys():
>     diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )
>     print(key + ":" + str(diff))
> ```
> ê°€ì¥ ë¨¼ì € MNISTë°ì´í„° ì…‹ì„ ì½ì€ ë‹¤ìŒ í›ˆë ¨ ë°ì´í„° ì¼ë¶€ë¥¼ ìˆ˜ì¹˜ ë¯¸ë¶„ìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸°ì™€ ì˜¤ì°¨ì—­ì „íŒŒë²•ìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸°ì˜ ì˜¤ì°¨ë¥¼ í™•ì¸í•œë‹¤. 
> - ì—¬ê¸°ì—ì„  ê° ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ì˜ ì°¨ì´ì˜ ì ˆëŒ“ê°’ì„ êµ¬í•˜ê³  ì´ë¥¼ í‰ê· í•œ ê°’ì´ ì˜¤ì°¨ê°€ ëœë‹¤. ì½”ë“œì˜ ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
> ```
> W1:4.049500550844403e-10
> b1:2.0780410401016312e-09
> W2:5.170073971086342e-09
> b2:1.397147032775048e-07
> ```
> 1ë²ˆì¬ ì¸µì˜ í¸í–¥ ì˜¤ì°¨ëŠ” 4.0e-10(0.00000000004)ì´ë‹¤. ì˜¤ì°¨ì—­ì „íŒŒë²•ìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸°ë„ ì˜¬ë°”ë¦„ì´ í™•ì¸ë˜ì–´ ì‹¤ìˆ˜ ì—†ì´ êµ¬í˜„í–ˆë‹¤ í•  ìˆ˜ ìˆë‹¤.
>
>> ìˆ˜ì¹˜ ë¯¸ë¶„ê³¼ ì˜¤ì°¨ì—­ì „íŒŒë²•ì˜ ê²°ê³¼ ì˜¤ì°¨ê°€ 0ì´ ë˜ëŠ” ì¼ì€ ë“œë¬¼ë‹¤.(ì»´í“¨í„°ê°€ í•  ìˆ˜ ìˆëŠ” ê³„ì‚°ì˜ ì •ë°€ë„ê°€ ìœ í•œí•˜ê¸° ë•Œë¬¸, 32ë¹„íŠ¸ ë¶€ë™ì†Œìˆ˜ì ) 
>> 
>> ì´ëŸ¬í•œ ì •ë°€ë„ì˜ í•œê³„ë¡œ ì¸í•´ ì˜¤ì°¨ëŠ” ëŒ€ë¶€ë¶„ 0ì´ ë˜ì§€ëŠ” ì•Šì§€ë§Œ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„í–ˆë‹¤ë©´ 0ì— ì•„ì£¼ ê·¼ì ‘í•œ ì‘ì€ ê°’ì´ ëœë‹¤. 
>> - ë§Œì•½ ê°’ì´ í¬ë‹¤ë©´ ì˜¤ì°¨ì—­ì „íŒŒë²•ì„ ì˜ëª» êµ¬í˜„í•œ ê²ƒì´ë¼ ì˜ì‹¬ í•´ë´ì•¼ í•œë‹¤.
>> 
> #### 5.7.4 ì˜¤ì°¨ì—­ì „íŒŒë²•ì„ ì‚¬ìš©í•œ í•™ìŠµ êµ¬í˜„í•˜ê¸°
> ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜¤ì°¨ì—­ì „íŒŒë²•ì„ ì‚¬ìš©í•œ ì‹ ê²½ë§ í•™ìŠµì„ êµ¬í˜„í•´ë³¸ë‹¤.
> - ì§€ê¸ˆê¹Œì§€ì™€ ë‹¤ë¥¸ì ì€ ê¸°ìš¸ê¸°ë¥¼ ì˜¤ì°¨ì—­ì „íŒŒë²•ìœ¼ë¡œ êµ¬í•˜ëŠ” ì ë¿ì´ë‹¤.
> ```Python
> import sys, os
> sys.path.append(os.pardir)
> 
> import numpy as np
> from dataset.mnist import load_mnist
> from two_layer_net import TwoLayerNet # ìœ„ì—ì„œ êµ¬í˜„í•œ 2ì¸µ ì‹ ê²½ë§
> 
> # ë°ì´í„° ì½ê¸°
> (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)
> 
> network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)
> 
> iters_num = 10000 # ë°˜ë³µ íšŸìˆ˜ë¥¼ ì ì ˆíˆ ì„¤ì •í•œë‹¤.
> train_size = x_train.shape[0]
> batch_size = 100 # ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°
> learning_rate = 0.1
> 
> train_loss_list = []
> train_acc_list = []
> test_acc_list = []
> 
> # 1ì—í­ë‹¹ ë°˜ë³µ ìˆ˜
> iter_per_epoch = max(train_size / batch_size, 1)
> 
> for i in range(iters_num):
>     # ë¯¸ë‹ˆë°°ì¹˜ íšë“
>     batch_mask = np.random.choice(train_size, batch_size)
>     x_batch = x_train[batch_mask]
>     t_batch = t_train[batch_mask]
>     
>     # ê¸°ìš¸ê¸° ê³„ì‚°
>     # grad = network.numerical_gradient(x_batch, t_batch) # ìˆ˜ì¹˜ ë¯¸ë¶„ ë°©ì‹
>     grad = network.gradient(x_batch, t_batch) # ì˜¤ì°¨ì—­ì „íŒŒë²• ë°©ì‹(í›¨ì”¬ ë¹ ë¥´ë‹¤)
>     
>     # ë§¤ê°œë³€ìˆ˜ ê°±ì‹ 
>     for key in ('W1', 'b1', 'W2', 'b2'):
>         network.params[key] -= learning_rate * grad[key]
>     
>     # í•™ìŠµ ê²½ê³¼ ê¸°ë¡
>     loss = network.loss(x_batch, t_batch)
>     train_loss_list.append(loss)
>     
>     # 1ì—í­ë‹¹ ì •í™•ë„ ê³„ì‚°
>     if i % iter_per_epoch == 0:
>         train_acc = network.accuracy(x_train, t_train)
>         test_acc = network.accuracy(x_test, t_test)
>         train_acc_list.append(train_acc)
>         test_acc_list.append(test_acc)
>         print(train_acc, test_acc)
> ```
> 
> #### 5.8 ì •ë¦¬
> ê³„ì‚° ê·¸ë˜í”„ë¥¼ í•™ìŠµí•˜ê³  ì˜¤ì°¨ì—­ì „íŒŒë²•ì— ëŒ€í•´ í•™ìŠµ í•˜ì˜€ë‹¤(ê³„ì¸µ : ReLU ê³„ì¸µ, Softmax-with-Loss ê³„ì¸µ, Affine ê³„ì¸µ, Softmax ê³„ì¸µ)
> 
> ëª¨ë“  ê³„ì¸µì—ì„œ forwardì™€ backward ë©”ì„œë“œë¥¼ êµ¬í˜„í•˜ë©° ì „ìëŠ” ë°ì´í„° ìˆœë°©í–¥ ì „íŒŒ, í›„ìëŠ” ì—­ë°©í–¥ ì „íŒŒí•¨ìœ¼ë¡œì¨ ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬í• ìˆ˜ ìˆë‹¤.
> 
> ì´ì™€ê°™ì´ ê³„ì¸µìœ¼ë¡œ ëª¨ë“ˆí™” í•˜ì—¬ ì‹ ê²½ë§ì˜ ê³„ì¸µì„ ììœ ë¡­ê²Œ ì¡°í•©í•´ ì›í•˜ëŠ” ì‹ ê²½ë§ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.
> 
> **ì´ë²ˆ ì¥ì—ì„œ ë°°ìš´ ë‚´ìš©**
> - ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì´ìš©í•˜ë©´ ê³„ì‚° ê³¼ì •ì„ ì‹œê°ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.
> 
> - ê³„ì‚° ê·¸ë˜í”„ì˜ ë…¸ë“œëŠ” êµ­ì†Œì  ê³„ì‚°ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. êµ­ì†Œì  ê³„ì‚°ì„ ì¡°í•©í•´ ì „ì²´ ê³„ì‚°ì„ êµ¬ì„±í•œë‹¤.
> 
> - ê³„ì‚° ê·¸ë˜í”„ì˜ ìˆœì „íŒŒëŠ” í†µìƒì˜ ê³„ì‚°ì„ ìˆ˜í–‰í•œë‹¤. í•œí¸, ê³„ì‚° ê·¸ë˜í”„ì˜ ì—­ì „íŒŒë¡œëŠ” ê° ë…¸ë“œì˜ ë¯¸ë¶„ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.
> 
> - ì‹ ê²½ë§ì˜ êµ¬ì„± ìš”ì†Œë¥¼ ê³„ì¸µìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ê¸°ìš¸ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤(ì˜¤ì°¨ì—­ì „íŒŒë²•)
> 
> - ìˆ˜ì¹˜ ë¯¸ë¶„ê³¼ ì˜¤ì°¨ì—­ì „íŒŒë²•ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ë©´ ì˜¤ì°¨ì—­ì „íŒŒë²•ì˜ êµ¬í˜„ì— ì˜ëª»ì´ ì—†ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤(ê¸°ìš¸ê¸° í™•ì¸)
>  
4/15
