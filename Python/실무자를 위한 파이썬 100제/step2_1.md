### 2021년이 왔어요...

> 2021/1/1
---
> 일단 어제 하던 1강 내용을 그냥 다시 해보기로 했다.
>
> bs4쪽 내용과 selenium 내용이라 이미 할줄 알아서 넘어갈라고 했는데.
>
> 아직 크롤링해본적 없는 싸이트들로 실습을 하길래 그냥 해봤다.
>
> 사용자가 입력한 키워드로 구글 뉴스를 클리핑 하는 함수를 작성 하였다.
> ```Python
> parse.quote(search_keyword) # 개인적으로 가장 중요한 부분이라고 생각한다.
> parse.unquote(search_keyword) # 디코딩은 뭐 앞에 un붙이면 된다.
> ```
> 위 코드는 사용자가 입력한 str변수를 url인코딩 시켜준다. 
>
> 위 함수를 이용해 인코딩한 text를 url 부분에 적절히 배치시키면 원하는 기사를 검색한 페이지로 갈 수 있다.
>
> 그 다음 내용들은 try/except를 이용한 누락값을 채워주는 부분과 bs4의 find,select 를 이용해
>
> div, a, span, time ...등의 class값을 이용한 원하는 값을 가져오는 내용들이다.
>
> 이 과정에서 간혹 None인 값이 있다면 오류가 발생하기에 위에서 try/except를 이용하도록 수정 했다.(이부분은 책과 다르다.)
>
> 전체 과정을 구글 뉴스만 클리핑 하는 함수로 작성 했다.
>
> 딕셔너리 형으로 반환한다.
>
> 다음내용은 selenium 이용해 다나와에서 로그인하고 관심목록 가져오는 것이다.
>
> 사실 이부분은 전에 알리익스프레스의 탑 카테고리 상품들을 추출해 엑셀로 저장하는 것을 실습할때 한것이랑 크게 다른것이 없어서
>
> 다음내용인 '한국은행 경제통계시스템 통계지표 활용해보기' 로 넘어간다.
>
> selenium 을 이용해 사용자가 입력한 text와 100대 경제지표를 비교해 매칭이 되는 것이 있다면 해당 페이지로 접속(클릭) 한뒤 테이블을 읽어서 엑셀로 저장한다.
>
> 셀레니움 사용은 사실 한번 하고나면 다음부터는 응용하기가 편한것 같다.
>
> 오늘은 여기까지.
>
> ps. 랜선때문에 계속 하루하루 날려먹는다... 월요일에 다시..
